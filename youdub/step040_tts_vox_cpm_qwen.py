#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‹±æ–‡è§†é¢‘è½¬ä¸­æ–‡é…éŸ³ TTS è„šæœ¬ âœ… æ”¯æŒå…¨å±€é»˜è®¤è¯­éŸ³å…‹éš† + éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥

è¯¥è„šæœ¬ç”¨äºå°†å·²ç¿»è¯‘çš„è‹±æ–‡è§†é¢‘ç‰‡æ®µï¼ˆJSON æ ¼å¼ï¼‰æ‰¹é‡åˆæˆä¸ºä¸­æ–‡é…éŸ³éŸ³é¢‘ï¼Œ
ä½¿ç”¨ VoxCPM æ¨¡å‹è¿›è¡Œè¯­éŸ³ç”Ÿæˆï¼Œå¹¶é€šè¿‡ Resemblyzer è¿›è¡ŒéŸ³è‰²ä¸€è‡´æ€§æ ¡éªŒï¼Œ
ç¡®ä¿æ‰€æœ‰ç”Ÿæˆçš„è¯­éŸ³ç‰‡æ®µåœ¨éŸ³è‰²ä¸Šä¸é¢„è®¾çš„å…¨å±€å‚è€ƒè¯­éŸ³ï¼ˆlkw_cloned.wavï¼‰ä¿æŒä¸€è‡´ã€‚

åŠŸèƒ½äº®ç‚¹ï¼š
- ğŸ™ï¸ å¼ºåˆ¶ä½¿ç”¨å…¨å±€è¯­éŸ³å…‹éš†ï¼ˆvoice/lkw_cloned.wav + lkw_cloned.txtï¼‰
- ğŸ” éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆåŸºäº Resemblyzer å£°çº¹åµŒå…¥ï¼‰
- â±ï¸ è‡ªåŠ¨å‹ç¼©è¶…é•¿ TTS éŸ³é¢‘ä»¥åŒ¹é…åŸå§‹è§†é¢‘æ—¶é—´è½´ï¼ˆç»ä¸æ‹‰ä¼¸ï¼ï¼‰
- ğŸ§ è‡ªåŠ¨æ··åˆä¼´å¥ï¼ˆaudio_instruments.wavï¼‰ç”Ÿæˆæœ€ç»ˆéŸ³é¢‘
- ğŸ”„ æ”¯æŒå•è§†é¢‘å¤„ç†æˆ–æ‰¹é‡å¤„ç†æ•´ä¸ªç›®å½•

ä½œè€…: Advanced TTS Team  
åˆ›å»ºæ—¥æœŸ: 2026-01-04  
ä¾èµ–é¡¹: voxcpm, resemblyzer, librosa, loguru, soundfile, audiostretchy (å¯é€‰), youdub (å¯é€‰)  
"""

import json
import os
import re
import sys
import traceback
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from dotenv import load_dotenv

import librosa
from loguru import logger

# åŠ è½½ .env é…ç½®ï¼ˆè‹¥ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
# load_dotenv()

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥æ¨¡å—æœç´¢è·¯å¾„ï¼Œä¾¿äºå¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ========================
# ğŸ¯ æ¨¡å—å¯¼å…¥ï¼šå¤„ç†ç¼ºå¤±ä¾èµ–çš„é™çº§æ–¹æ¡ˆ
# ========================

# å°è¯•å¯¼å…¥ youdub.utilsï¼Œè‹¥å¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°å®ç°
try:
    from youdub.utils import save_wav, save_wav_norm
except ImportError:
    logger.warning("youdub.utils æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨æœ¬åœ°å®ç°")

    import scipy.io.wavfile

    def save_wav(wav: np.ndarray, path: str, sample_rate: int = 16000):
        """å°†å½’ä¸€åŒ–çš„ [-1, 1] æµ®ç‚¹éŸ³é¢‘ä¿å­˜ä¸º 16-bit WAV æ–‡ä»¶"""
        wav = np.clip(wav, -1.0, 1.0)
        scipy.io.wavfile.write(path, sample_rate, (wav * 32767).astype(np.int16))

    def save_wav_norm(wav: np.ndarray, path: str, sample_rate: int = 16000):
        """å…ˆå½’ä¸€åŒ–å†ä¿å­˜ WAVï¼Œé¿å…å‰Šæ³¢"""
        if len(wav) > 0:
            wav = wav / np.max(np.abs(wav)) * 0.95
        save_wav(wav, path, sample_rate)


# ========================
# ğŸ¯ å…¨å±€é»˜è®¤è¯­éŸ³å…‹éš†é…ç½®
# ========================
DEFAULT_VOICE_WAV = os.path.join("voice", "lkw_cloned.wav")
DEFAULT_VOICE_TXT = os.path.join("voice", "lkw_cloned.txt")

# æ ¡éªŒå…¨å±€å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬æ˜¯å¦å­˜åœ¨
if not os.path.exists(DEFAULT_VOICE_WAV):
    logger.error(f"âŒ å…¨å±€å…‹éš†éŸ³é¢‘æ–‡ä»¶ç¼ºå¤±: {DEFAULT_VOICE_WAV}")
    sys.exit(1)
if not os.path.exists(DEFAULT_VOICE_TXT):
    logger.error(f"âŒ å…¨å±€å…‹éš†æ–‡æœ¬æ–‡ä»¶ç¼ºå¤±: {DEFAULT_VOICE_TXT}")
    sys.exit(1)

with open(DEFAULT_VOICE_TXT, 'r', encoding='utf-8') as f:
    GLOBAL_PROMPT_TEXT = f.read().strip()

if not GLOBAL_PROMPT_TEXT:
    logger.error(f"âŒ å…¨å±€å…‹éš†æ–‡æœ¬ä¸ºç©º: {DEFAULT_VOICE_TXT}")
    sys.exit(1)

logger.info(f"ğŸ¤ å…¨å±€é»˜è®¤è¯­éŸ³å…‹éš†å·²å¯ç”¨: {DEFAULT_VOICE_WAV}")


# ========================
# ğŸ¯ Resemblyzer éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥æ¨¡å—
# ========================
HAS_RESEMBLYZER = False
resemblyzer_encoder = None
GLOBAL_REFERENCE_EMBEDDING = None

try:
    from resemblyzer import VoiceEncoder
    from resemblyzer.audio import preprocess_wav

    resemblyzer_encoder = VoiceEncoder("cpu")  # å¯æ”¹ä¸º "cuda" å¯ç”¨ GPU
    ref_wav = preprocess_wav(DEFAULT_VOICE_WAV)
    GLOBAL_REFERENCE_EMBEDDING = resemblyzer_encoder.embed_utterance(ref_wav)
    HAS_RESEMBLYZER = True
    logger.info("âœ… å£°çº¹ä¸€è‡´æ€§æ£€æŸ¥å·²å¯ç”¨ï¼ˆä½¿ç”¨ Resemblyzerï¼‰")
except Exception as e:
    logger.warning(f"âš ï¸ Resemblyzer åŠ è½½å¤±è´¥ï¼ˆå°†è·³è¿‡éŸ³è‰²æ£€æŸ¥ï¼‰: {e}")
    HAS_RESEMBLYZER = False


def is_voice_consistent(generated_wav_path: str, threshold: float = 0.6) -> bool:
    """
    åˆ¤æ–­ç”Ÿæˆçš„è¯­éŸ³ç‰‡æ®µä¸å…¨å±€å‚è€ƒè¯­éŸ³çš„éŸ³è‰²æ˜¯å¦ä¸€è‡´ã€‚

    å‚æ•°:
        generated_wav_path (str): ç”ŸæˆéŸ³é¢‘çš„è·¯å¾„ã€‚
        threshold (float): ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ŒèŒƒå›´ [0,1]ï¼Œé»˜è®¤ 0.6ã€‚

    è¿”å›:
        bool: True è¡¨ç¤ºéŸ³è‰²ä¸€è‡´ï¼ˆæˆ–æ— æ³•æ£€æŸ¥æ—¶å®¹é”™é€šè¿‡ï¼‰ï¼ŒFalse è¡¨ç¤ºä¸ä¸€è‡´ã€‚
    """
    if not HAS_RESEMBLYZER or GLOBAL_REFERENCE_EMBEDDING is None:
        return True  # æ— æ³•æ£€æŸ¥æ—¶è§†ä¸ºé€šè¿‡

    try:
        gen_wav = preprocess_wav(generated_wav_path)
        if len(gen_wav) < 0.5 * 16000:  # å°‘äº 0.5 ç§’ï¼Œè·³è¿‡æ£€æŸ¥
            return True
        gen_embedding = resemblyzer_encoder.embed_utterance(gen_wav)
        similarity = float(np.dot(GLOBAL_REFERENCE_EMBEDDING, gen_embedding))
        logger.debug(f"   ğŸ” éŸ³è‰²ç›¸ä¼¼åº¦: {similarity:.3f} (é˜ˆå€¼={threshold})")
        return similarity >= threshold
    except Exception as e:
        logger.warning(f"   âš ï¸ éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
        return True  # å®¹é”™å¤„ç†ï¼šæ£€æŸ¥å¤±è´¥ä¹Ÿè§†ä¸ºé€šè¿‡


# ========================
# ğŸ¯ VoxCPM TTS æ¨¡å‹åŠ è½½
# ========================
VOXCPM_MODEL = None
HAS_VOXCPM = False

try:
    from voxcpm import VoxCPM
    logger.info("âœ… æ­£åœ¨åŠ è½½ VoxCPM æ¨¡å‹...")
    VOXCPM_MODEL = VoxCPM.from_pretrained("openbmb/VoxCPM-0.5B")
    HAS_VOXCPM = True
    logger.info("âœ… VoxCPM æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    logger.error(f"âŒ VoxCPM æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    HAS_VOXCPM = False


# ========================
# ğŸ¯ å¯é€‰åŠŸèƒ½ï¼šæ–‡æœ¬è§„èŒƒåŒ– & éŸ³é¢‘æ‹‰ä¼¸
# ========================
HAS_TEXTNORM = False
try:
    from youdub.cn_tx import TextNorm
    normalizer = TextNorm()
    HAS_TEXTNORM = True
except ImportError:
    logger.warning("âš ï¸ æ–‡æœ¬è§„èŒƒåŒ–æ¨¡å—æœªæ‰¾åˆ°")

HAS_AUDIOSTRETCHY = False
try:
    from audiostretchy.stretch import stretch_audio
    HAS_AUDIOSTRETCHY = True
except ImportError:
    logger.warning("âš ï¸ audiostretchyæœªå®‰è£…ï¼Œå°†ä½¿ç”¨librosa")


@dataclass
class TTSConfig:
    """TTS åˆæˆé…ç½®å‚æ•°"""
    sample_rate: int = 16000


def stretch_audio_librosa(wav_path: str, target_path: str, ratio: float, sample_rate: int = 16000) -> bool:
    """
    ä½¿ç”¨ librosa å®ç°éŸ³é¢‘æ—¶é—´æ‹‰ä¼¸ï¼ˆä»…ç”¨äºå‹ç¼©ï¼Œratio < 1.0ï¼‰ã€‚

    å‚æ•°:
        wav_path (str): è¾“å…¥éŸ³é¢‘è·¯å¾„ã€‚
        target_path (str): è¾“å‡ºéŸ³é¢‘è·¯å¾„ã€‚
        ratio (float): æ‹‰ä¼¸æ¯”ä¾‹ï¼ˆ<1 ä¸ºåŠ é€Ÿï¼Œ>1 ä¸ºå‡é€Ÿï¼‰ã€‚
        sample_rate (int): é‡‡æ ·ç‡ã€‚

    è¿”å›:
        bool: æ˜¯å¦æˆåŠŸã€‚
    """
    try:
        wav, sr = librosa.load(wav_path, sr=sample_rate)
        wav_stretched = librosa.effects.time_stretch(wav, rate=ratio)
        import soundfile as sf
        sf.write(target_path, wav_stretched, sr)
        return True
    except Exception as e:
        logger.error(f"librosaæ—¶é—´æ‹‰ä¼¸å¤±è´¥: {e}")
        return False


def adjust_audio_length(wav_path: str, desired_length: float, sample_rate: int = 16000) -> Tuple[np.ndarray, float]:
    """
    è°ƒæ•´éŸ³é¢‘é•¿åº¦ï¼šä»…åœ¨ TTS éŸ³é¢‘è¶…é•¿æ—¶è¿›è¡Œå‹ç¼©ï¼ˆç»ä¸æ‹‰ä¼¸ï¼ï¼‰ã€‚

    å‚æ•°:
        wav_path (str): è¾“å…¥éŸ³é¢‘è·¯å¾„ã€‚
        desired_length (float): ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰ã€‚
        sample_rate (int): é‡‡æ ·ç‡ã€‚

    è¿”å›:
        Tuple[np.ndarray, float]: (è°ƒæ•´åçš„éŸ³é¢‘æ•°ç»„, å®é™…æ—¶é•¿)
    """
    try:
        wav, sr = librosa.load(wav_path, sr=sample_rate)
        current_length = len(wav) / sample_rate

        if current_length <= 0:
            logger.error(f"éŸ³é¢‘é•¿åº¦ä¸º0: {wav_path}")
            return np.zeros(int(desired_length * sample_rate)), desired_length

        if current_length <= desired_length:
            return wav, current_length

        # é™åˆ¶æœ€å°å‹ç¼©æ¯”ä¾‹ä¸º 0.85ï¼ˆé¿å…è¿‡åº¦å¤±çœŸï¼‰
        speed_factor = max(desired_length / current_length, 0.85)
        logger.warning(f"âš ï¸ è¶…æ—¶å‹ç¼©: {current_length:.2f}s â†’ {desired_length:.2f}s (å› å­={speed_factor:.2f})")

        target_path = wav_path.replace('.wav', '_adjusted_temp.wav')
        success = False

        if HAS_AUDIOSTRETCHY:
            try:
                stretch_audio(wav_path, target_path, ratio=speed_factor, sample_rate=sample_rate)
                success = True
            except Exception as e:
                logger.debug(f"audiostretchyå¤±è´¥: {e}")

        if not success:
            if not stretch_audio_librosa(wav_path, target_path, speed_factor, sample_rate):
                return wav, current_length

        if os.path.exists(target_path):
            wav_adjusted, _ = librosa.load(target_path, sr=sample_rate)
            actual_len = len(wav_adjusted) / sample_rate
            os.remove(target_path)
            return wav_adjusted, actual_len

        return wav, current_length

    except Exception as e:
        logger.error(f"éŸ³é¢‘é•¿åº¦è°ƒæ•´å¤±è´¥: {e}")
        return np.zeros(int(desired_length * sample_rate)), desired_length


def generate_voxcpm_audio(text: str, output_path: str, speaker_wav: Optional[str],
                          target_duration: Optional[float] = None) -> bool:
    """
    ä½¿ç”¨ VoxCPM æ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚

    å‚æ•°:
        text (str): å¾…åˆæˆçš„ä¸­æ–‡æ–‡æœ¬ã€‚
        output_path (str): è¾“å‡ºéŸ³é¢‘è·¯å¾„ã€‚
        speaker_wav (str or None): å‚è€ƒè¯­éŸ³è·¯å¾„ã€‚
        target_duration (float or None): ç›®æ ‡æ—¶é•¿ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼Œä¸å½±å“ç”Ÿæˆï¼‰ã€‚

    è¿”å›:
        bool: æ˜¯å¦æˆåŠŸç”Ÿæˆã€‚
    """
    global VOXCPM_MODEL

    if not HAS_VOXCPM or VOXCPM_MODEL is None:
        logger.error("âŒ VoxCPM æ¨¡å‹ä¸å¯ç”¨")
        return False

    if os.path.exists(output_path):
        return True

    logger.debug(f"ğŸ—£ï¸ VoxCPM ç”Ÿæˆ: \"{text[:50]}...\" (ç›®æ ‡æ—¶é•¿: {target_duration:.2f}s)")

    # === å…³é”®ï¼šå®‰å…¨åŠ è½½å‚è€ƒæ–‡æœ¬ï¼ˆå¿…é¡»ä¸éŸ³é¢‘è¯­è¨€ä¸€è‡´ï¼‰===
    prompt_text = None
    if speaker_wav and os.path.exists(speaker_wav):
        base = os.path.splitext(speaker_wav)[0]
        # ä¼˜å…ˆä½¿ç”¨ _CLONE.txtï¼ˆæ ‡å‡†è¾“å‡ºï¼‰
        candidate_txts = [
            base + "_CLONE.txt",
            base + ".txt"
        ]
        for txt_candidate in candidate_txts:
            if os.path.exists(txt_candidate) and os.path.getsize(txt_candidate) > 0:
                try:
                    with open(txt_candidate, 'r', encoding='utf-8') as f:
                        prompt_text = f.read().strip()
                    if prompt_text:
                        logger.debug(f"ğŸ“œ ä½¿ç”¨å‚è€ƒæ–‡æœ¬: {prompt_text[:40]}...")
                        break  # æ‰¾åˆ°å°±åœæ­¢
                except Exception as e:
                    logger.warning(f"âš ï¸ å‚è€ƒæ–‡æœ¬åŠ è½½å¤±è´¥ ({txt_candidate}): {e}")
        
        if not prompt_text:
            logger.warning(f"âš ï¸ æœ‰å‚è€ƒéŸ³é¢‘ä½†æ— æœ‰æ•ˆæ–‡æœ¬ï¼Œå°†ä½¿ç”¨å…¨å±€é»˜è®¤æ–‡æœ¬: {speaker_wav}")
            # ä½¿ç”¨å…¨å±€é»˜è®¤æ–‡æœ¬ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            prompt_text = GLOBAL_PROMPT_TEXT
            logger.info(f"ğŸ“œ å›é€€åˆ°å…¨å±€é»˜è®¤æ–‡æœ¬")
    else:
        speaker_wav = None
        prompt_text = None

    try:
        wav = VOXCPM_MODEL.generate(
            text=text,                    # â† ä¸­æ–‡ï¼ˆç›®æ ‡è¯­è¨€ï¼‰
            prompt_wav_path=speaker_wav,  # â† å‚è€ƒéŸ³é¢‘ï¼ˆéŸ³è‰²æ¥æºï¼‰
            prompt_text=prompt_text,      # â† å‚è€ƒæ–‡æœ¬ï¼ˆä¸éŸ³é¢‘åŒ¹é…ï¼‰
            cfg_value=2.0,
            inference_timesteps=10,
            normalize=True,
            denoise=True,
            retry_badcase=True,
            retry_badcase_max_times=3,
            retry_badcase_ratio_threshold=6.0,
        )
        if isinstance(wav, list):
            wav = np.array(wav, dtype=np.float32)
        elif not isinstance(wav, np.ndarray):
            wav = np.array(wav)
        import soundfile as sf
        sf.write(output_path, wav, 16000)
        return True
    except Exception as e:
        logger.error(f"VoxCPM ç”Ÿæˆå¤±è´¥: {e}")
        return False


def unload_voxcpm_model():
    """
    å¸è½½ VoxCPM å’Œ Resemblyzer æ¨¡å‹ï¼Œé‡Šæ”¾å†…å­˜å’Œæ˜¾å­˜èµ„æºã€‚
    """
    global VOXCPM_MODEL, resemblyzer_encoder, GLOBAL_REFERENCE_EMBEDDING
    import gc
    import torch
    
    logger.info("âœ… æ­£åœ¨å¸è½½ VoxCPM ç›¸å…³èµ„æº...")
    
    # å¸è½½ VoxCPM æ¨¡å‹
    if VOXCPM_MODEL is not None:
        logger.info("   ğŸ—£ï¸ å¸è½½ VoxCPM æ¨¡å‹...")
        # ç§»åˆ°CPUé‡Šæ”¾GPUèµ„æº
        if hasattr(VOXCPM_MODEL, 'to'):
            VOXCPM_MODEL.to('cpu')
        del VOXCPM_MODEL
        VOXCPM_MODEL = None
    
    # å¸è½½ Resemblyzer ç¼–ç å™¨
    if resemblyzer_encoder is not None:
        logger.info("   ğŸ¤ å¸è½½ Resemblyzer ç¼–ç å™¨...")
        del resemblyzer_encoder
        resemblyzer_encoder = None
    
    # é‡Šæ”¾å…¨å±€å‚è€ƒåµŒå…¥
    if GLOBAL_REFERENCE_EMBEDDING is not None:
        logger.info("   ğŸ“Š é‡Šæ”¾å…¨å±€å‚è€ƒåµŒå…¥...")
        del GLOBAL_REFERENCE_EMBEDDING
        GLOBAL_REFERENCE_EMBEDDING = None
    
    # æ¸…ç†PyTorchç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    gc.collect()
    
    logger.info("âœ… VoxCPM ç›¸å…³èµ„æºå·²å…¨éƒ¨å¸è½½")


def preprocess_text(text: str) -> str:
    """
    å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œæå‡ TTS åˆæˆè´¨é‡ã€‚

    å¤„ç†å†…å®¹ï¼š
    - ç¼©å†™å±•å¼€ï¼ˆå¦‚ AI â†’ äººå·¥æ™ºèƒ½ï¼‰
    - å¤§å†™å­—æ¯åˆ†éš”ï¼ˆå¦‚ "HelloWorld" â†’ "Hello World"ï¼‰
    - æ•°å­—ä¸å­—æ¯é—´åŠ ç©ºæ ¼
    - æ–‡æœ¬è§„èŒƒåŒ–ï¼ˆè‹¥æ¨¡å—å¯ç”¨ï¼‰

    å‚æ•°:
        text (str): åŸå§‹æ–‡æœ¬ã€‚

    è¿”å›:
        str: é¢„å¤„ç†åçš„æ–‡æœ¬ã€‚
    """
    if not text:
        return ""
    text = text.strip()
    replacements = {
        'AI': 'äººå·¥æ™ºèƒ½', 'GPT': 'G P T', 'API': 'A P I', 'UI': 'U I', 'UX': 'U X',
        'CEO': 'C E O', 'CPU': 'C P U', 'GPU': 'G P U'
    }
    for k, v in replacements.items():
        text = text.replace(k, v)
    # åœ¨å¤§å†™å­—æ¯å‰åŠ ç©ºæ ¼ï¼ˆé™¤äº†å¼€å¤´ï¼‰
    text = re.sub(r'(?<!^)([A-Z])', r' \1', text)
    if HAS_TEXTNORM:
        try:
            text = normalizer(text)
        except Exception:
            pass
    # æ•°å­—ä¸å­—æ¯ä¹‹é—´åŠ ç©ºæ ¼
    text = re.sub(r'(?<=[a-zA-Z])(?=\d)|(?<=\d)(?=[a-zA-Z])', ' ', text)
    return re.sub(r'\s+', ' ', text).strip()


def generate_wavs(folder: str, config: Optional[TTSConfig] = None) -> bool:
    """
    ä¸ºå•ä¸ªè§†é¢‘æ–‡ä»¶å¤¹ç”Ÿæˆ TTS éŸ³é¢‘å¹¶æ··åˆä¼´å¥ã€‚

    ç›®å½•ç»“æ„è¦æ±‚ï¼š
    - folder/
        - translation.json       â† å¿…é¡»ï¼šå« 'translation', 'start', 'end'
        - audio_vocals.wav       â† å¯é€‰ï¼šåŸå§‹äººå£°ï¼ˆç”¨äºå¯¹é½æ€»æ—¶é•¿ï¼‰
        - audio_instruments.wav  â† å¯é€‰ï¼šä¼´å¥ï¼ˆç”¨äºæ··åˆï¼‰

    ç”Ÿæˆæ–‡ä»¶ï¼š
    - wavs/0000.wav ...        â† æ¯ä¸ªç‰‡æ®µ
    - audio_tts.wav            â† çº¯ä¸­æ–‡é…éŸ³
    - audio_combined.wav       â† é…éŸ³ + ä¼´å¥ï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰

    å‚æ•°:
        folder (str): è§†é¢‘å¤„ç†ç›®å½•ã€‚
        config (TTSConfig): TTS é…ç½®ã€‚

    è¿”å›:
        bool: æ˜¯å¦æˆåŠŸç”Ÿæˆ combined éŸ³é¢‘ã€‚
    """
    if config is None:
        config = TTSConfig()

    folder_name = os.path.basename(folder)
    logger.info(f"\nğŸ¬ æ­£åœ¨å¤„ç†è§†é¢‘: {folder_name}")

    transcript_path = os.path.join(folder, 'translation.json')
    output_folder = os.path.join(folder, 'wavs')
    combined_path = os.path.join(folder, 'audio_combined.wav')

    if not os.path.exists(transcript_path):
        logger.error(f"âŒ ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {transcript_path}")
        return False
    if os.path.exists(combined_path):
        logger.info(f"â­ï¸ å·²å­˜åœ¨ï¼Œè·³è¿‡: {folder_name}")
        return True
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    with open(transcript_path, 'r', encoding='utf-8') as f:
        transcript = json.load(f)
    if not transcript:
        logger.error(f"âŒ ç¿»è¯‘æ–‡ä»¶ä¸ºç©º")
        return False

    audio_vocals_path = os.path.join(folder, 'audio_vocals.wav')
    original_audio_duration = librosa.get_duration(path=audio_vocals_path) if os.path.exists(audio_vocals_path) else max(line.get('end', 0) for line in transcript)
    logger.info(f"â±ï¸ åŸå§‹éŸ³é¢‘æ€»æ—¶é•¿: {original_audio_duration:.2f}ç§’")

    full_wav = np.zeros(0, dtype=np.float32)

    for i, line in enumerate(transcript):
        text = line.get('translation', '').strip()
        if not text:
            continue

        speaker = line.get('speaker', 'SPEAKER_00')
        processed_text = preprocess_text(text)

        logger.info(f"\nğŸ—£ï¸ ç‰‡æ®µ [{i+1}/{len(transcript)}] | è¯´è¯äºº: {speaker}")
        logger.info(f"ğŸ”¤ åˆæˆæ–‡æœ¬: {processed_text[:45]}{'...' if len(processed_text) > 45 else ''}")

        # å¼ºåˆ¶ä½¿ç”¨å…¨å±€é»˜è®¤è¯­éŸ³å…‹éš†
        speaker_wav = DEFAULT_VOICE_WAV
        logger.info("ğŸ¤ ä½¿ç”¨å…¨å±€é»˜è®¤éŸ³è‰²: lkw_cloned")

        # è®¡ç®—ç›®æ ‡æ—¶é•¿ï¼ˆä¼˜å…ˆä½¿ç”¨ VAD æ—¶é•¿ï¼Œå¦åˆ™ç”¨åŸå§‹ç‰‡æ®µæ—¶é•¿ï¼‰
        start = float(line.get('start', 0))
        end = float(line.get('end', 0))
        raw_duration = end - start
        vad_duration = line.get('vad_duration')
        target_duration = min(float(vad_duration), raw_duration) if vad_duration else raw_duration
        logger.info(f"â±ï¸ åŸè§†é¢‘æ—¶é•¿: {raw_duration:.2f}s")

        # ç”ŸæˆéŸ³é¢‘ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        output_path = os.path.join(output_folder, f'{str(i).zfill(4)}.wav')
        success = False
        max_retries = 2

        for attempt in range(max_retries + 1):
            if attempt > 0:
                logger.warning(f"   ğŸ” ç¬¬ {attempt} æ¬¡é‡è¯•ç”Ÿæˆï¼ˆéŸ³è‰²ä¸ä¸€è‡´ï¼‰")

            if generate_voxcpm_audio(processed_text, output_path, speaker_wav, target_duration):
                if is_voice_consistent(output_path, threshold=0.6):
                    success = True
                    break
                else:
                    logger.warning("   âŒ éŸ³è‰²ä¸ä¸€è‡´ï¼Œå°†é‡è¯•...")
                    if os.path.exists(output_path):
                        os.remove(output_path)
            else:
                break  # ç”Ÿæˆå¤±è´¥ä¸å†é‡è¯•

        if not success:
            logger.error(f"âŒ ç‰‡æ®µ {i+1} ç”Ÿæˆå¤±è´¥æˆ–éŸ³è‰²ä¸ä¸€è‡´ï¼Œè·³è¿‡")
            continue

        # éŸ³é¢‘åå¤„ç†ï¼šå¯¹é½æ—¶é—´è½´
        try:
            gen_wav, sr = librosa.load(output_path, sr=config.sample_rate)
            gen_duration = len(gen_wav) / sr
            logger.info(f"   ğŸ™ï¸ TTSç”Ÿæˆæ—¶é•¿: {gen_duration:.2f}s")

            wav_adjusted, final_duration = adjust_audio_length(output_path, target_duration, config.sample_rate)
            logger.info(f"   ğŸ“ æœ€ç»ˆéŸ³é¢‘æ—¶é•¿: {final_duration:.2f}s")

            # æ’å…¥é™éŸ³å¯¹é½èµ·å§‹æ—¶é—´
            current_time = len(full_wav) / config.sample_rate
            if start > current_time:
                silence_samples = int((start - current_time) * config.sample_rate)
                if silence_samples > 0:
                    full_wav = np.concatenate([full_wav, np.zeros(silence_samples, dtype=np.float32)])
            elif start < current_time:
                target_samples = int(start * config.sample_rate)
                if target_samples < len(full_wav):
                    full_wav = full_wav[:target_samples]

            # é™åˆ¶ç»“æŸæ—¶é—´ï¼ˆé¿å…ç‰‡æ®µé‡å ï¼‰
            max_end_samples = int((end + 0.2) * config.sample_rate)
            current_samples = len(full_wav)
            if current_samples + len(wav_adjusted) > max_end_samples:
                allowed = max_end_samples - current_samples
                if allowed > 0:
                    wav_adjusted = wav_adjusted[:allowed]
                else:
                    wav_adjusted = np.zeros(0)

            if len(wav_adjusted) > 0:
                full_wav = np.concatenate([full_wav, wav_adjusted])

        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç‰‡æ®µ {i+1} å¤±è´¥: {e}")
            traceback.print_exc()
            continue

    # ä¿å­˜æœ€ç»ˆ TTS éŸ³é¢‘
    if len(full_wav) == 0:
        return False

    target_samples = int(original_audio_duration * config.sample_rate)
    if len(full_wav) < target_samples:
        full_wav = np.pad(full_wav, (0, target_samples - len(full_wav)), mode='constant')
    elif len(full_wav) > target_samples:
        full_wav = full_wav[:target_samples]

    # éŸ³é‡å¯¹é½ï¼ˆå‚è€ƒåŸäººå£°éŸ³é‡ï¼‰
    if os.path.exists(audio_vocals_path):
        try:
            vocal_wav, sr = librosa.load(audio_vocals_path, sr=config.sample_rate)
            if len(vocal_wav) > 0 and np.max(np.abs(full_wav)) > 0:
                full_wav = full_wav / np.max(np.abs(full_wav)) * np.max(np.abs(vocal_wav)) * 0.95
        except Exception as e:
            logger.warning(f"éŸ³é‡å¯¹é½å¤±è´¥: {e}")

    tts_path = os.path.join(folder, 'audio_tts.wav')
    save_wav(full_wav, tts_path, config.sample_rate)
    logger.info(f"ğŸ”Š TTSéŸ³é¢‘å·²ä¿å­˜: {tts_path}")

    # æ··åˆä¼´å¥
    instruments_path = os.path.join(folder, 'audio_instruments.wav')
    if os.path.exists(instruments_path):
        try:
            inst_wav, sr = librosa.load(instruments_path, sr=config.sample_rate)
            if len(full_wav) > len(inst_wav):
                inst_wav = np.pad(inst_wav, (0, len(full_wav) - len(inst_wav)), mode='constant')
            elif len(inst_wav) > len(full_wav):
                full_wav = np.pad(full_wav, (0, len(inst_wav) - len(full_wav)), mode='constant')
            combined = full_wav * 0.8 + inst_wav * 0.6  # é…éŸ³ 80%ï¼Œä¼´å¥ 60%
            combined_path = os.path.join(folder, 'audio_combined.wav')
            save_wav_norm(combined, combined_path, config.sample_rate)
            logger.info(f"ğŸ§ æ··åˆéŸ³é¢‘å·²ä¿å­˜: {combined_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ æ··åˆå¤±è´¥: {e}")
            return False
    else:
        logger.warning("âš ï¸ æ— ä¼´å¥æ–‡ä»¶ï¼Œä»…ä¿å­˜ TTS éŸ³é¢‘")
        return True


def generate_all_wavs_under_folder(root_folder: str) -> Dict[str, Any]:
    """
    éå†æ ¹ç›®å½•ï¼Œå¯¹æ‰€æœ‰åŒ…å« translation.json çš„å­æ–‡ä»¶å¤¹æ‰§è¡Œ TTS åˆæˆã€‚

    å‚æ•°:
        root_folder (str): æ ¹ç›®å½•è·¯å¾„ã€‚

    è¿”å›:
        Dict: ç»Ÿè®¡ç»“æœï¼Œå«æˆåŠŸ/å¤±è´¥/è·³è¿‡æ•°é‡ã€‚
    """
    results = {
        'total': 0,
        'processed': 0,
        'success': 0,
        'failed': 0,
        'failed_folders': [],
        'skipped': 0
    }
    for root, _, files in os.walk(root_folder):
        if 'translation.json' in files:
            results['total'] += 1
            if 'audio_combined.wav' in files:
                results['skipped'] += 1
                logger.info(f'â­ï¸ è·³è¿‡: {os.path.basename(root)}')
                continue
            results['processed'] += 1
            if generate_wavs(root):
                results['success'] += 1
            else:
                results['failed'] += 1
                results['failed_folders'].append(root)
    return results


def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å¯åŠ¨å¤„ç†æµç¨‹ã€‚
    
    ç”¨æ³•:
        python script.py --folder <å•ä¸ªè§†é¢‘ç›®å½•>
        python script.py --all [--root <æ ¹ç›®å½•>]
    """
    import argparse
    parser = argparse.ArgumentParser(description="è‹±æ–‡è§†é¢‘è½¬ä¸­æ–‡é…éŸ³ TTS è„šæœ¬")
    parser.add_argument('--folder', type=str, help="å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶å¤¹")
    parser.add_argument('--all', action='store_true', help="å¤„ç†æ ¹ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘")
    parser.add_argument('--root', type=str, default='videos', help="æ‰¹é‡å¤„ç†çš„æ ¹ç›®å½•ï¼ˆé»˜è®¤: videosï¼‰")
    args = parser.parse_args()

    # é…ç½®æ—¥å¿—æ ¼å¼
    logger.remove()
    logger.add(sys.stdout, level="INFO", format="<green>{time:MM-DD HH:mm:ss}</green> | <level>{level: <6}</level> | <cyan>{message}</cyan>")

    if not HAS_VOXCPM:
        logger.error("âŒ VoxCPM ä¸å¯ç”¨")
        sys.exit(1)

    if args.all or (not args.folder and not args.all):
        results = generate_all_wavs_under_folder(args.root if args.all else 'videos')
        logger.info("\n" + "="*50)
        logger.info(f"âœ… æˆåŠŸ: {results['success']}/{results['processed']} | â­ï¸ è·³è¿‡: {results['skipped']}")
        if results['failed'] > 0:
            logger.warning(f"âŒ å¤±è´¥: {results['failed']} ä¸ªè§†é¢‘")
            for f in results['failed_folders']:
                logger.warning(f"   - {f}")
    elif args.folder:
        folder_name = os.path.basename(args.folder)
        if os.path.exists(os.path.join(args.folder, 'audio_combined.wav')):
            logger.info(f"â­ï¸ è·³è¿‡: {folder_name}")
        else:
            logger.info(f"ğŸ¬ å¤„ç†: {folder_name}")
            generate_wavs(args.folder)


if __name__ == '__main__':
    main()