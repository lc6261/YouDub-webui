#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‹±æ–‡è§†é¢‘è½¬ä¸­æ–‡é…éŸ³ TTS è„šæœ¬ âœ… æ”¯æŒå…¨å±€é»˜è®¤è¯­éŸ³å…‹éš† + éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥

è¯¥è„šæœ¬ç”¨äºå°†å·²ç¿»è¯‘çš„è‹±æ–‡è§†é¢‘ç‰‡æ®µï¼ˆJSON æ ¼å¼ï¼‰æ‰¹é‡åˆæˆä¸ºä¸­æ–‡é…éŸ³éŸ³é¢‘ï¼Œ
ä½¿ç”¨ VoxCPM æ¨¡å‹è¿›è¡Œè¯­éŸ³ç”Ÿæˆï¼Œå¹¶é€šè¿‡ Resemblyzer è¿›è¡ŒéŸ³è‰²ä¸€è‡´æ€§æ ¡éªŒï¼Œ
ç¡®ä¿æ‰€æœ‰ç”Ÿæˆçš„è¯­éŸ³ç‰‡æ®µåœ¨éŸ³è‰²ä¸Šä¸é¢„è®¾çš„å…¨å±€å‚è€ƒè¯­éŸ³ï¼ˆlkw_cloned.wavï¼‰ä¿æŒä¸€è‡´ã€‚

åŠŸèƒ½äº®ç‚¹ï¼š
- ğŸ™ï¸ å¼ºåˆ¶ä½¿ç”¨å…¨å±€è¯­éŸ³å…‹éš†ï¼ˆvoice/lkw_cloned.wav + lkw_cloned.txtï¼‰
- ğŸ” éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆåŸºäº Resemblyzer å£°çº¹åµŒå…¥ï¼‰
- â±ï¸ è‡ªåŠ¨å‹ç¼©è¶…é•¿ TTS éŸ³é¢‘ä»¥åŒ¹é…åŸå§‹è§†é¢‘æ—¶é—´è½´ï¼ˆç»ä¸æ‹‰ä¼¸ï¼ï¼‰
- ğŸ§ è‡ªåŠ¨æ··åˆä¼´å¥ï¼ˆaudio_instruments.wavï¼‰ç”Ÿæˆæœ€ç»ˆéŸ³é¢‘
- ğŸ”„ æ”¯æŒå•è§†é¢‘å¤„ç†æˆ–æ‰¹é‡å¤„ç†æ•´ä¸ªç›®å½•

ä½œè€…: Advanced TTS Team  
åˆ›å»ºæ—¥æœŸ: 2026-01-04  
ä¾èµ–é¡¹: voxcpm, resemblyzer, librosa, loguru, soundfile, audiostretchy (å¯é€‰), youdub (å¯é€‰)  
"""

import json
import os
import re
import sys
import traceback
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from dotenv import load_dotenv

import librosa
from loguru import logger

# åŠ è½½ .env é…ç½®ï¼ˆè‹¥ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
# load_dotenv()

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥æ¨¡å—æœç´¢è·¯å¾„ï¼Œä¾¿äºå¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ========================
# ğŸ¯ æ¨¡å—å¯¼å…¥ï¼šå¤„ç†ç¼ºå¤±ä¾èµ–çš„é™çº§æ–¹æ¡ˆ
# ========================

# å°è¯•å¯¼å…¥ youdub.utilsï¼Œè‹¥å¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°å®ç°
try:
    from youdub.utils import save_wav, save_wav_norm
except ImportError:
    logger.warning("youdub.utils æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨æœ¬åœ°å®ç°")

    import scipy.io.wavfile

    def save_wav(wav: np.ndarray, path: str, sample_rate: int = 16000):
        """å°†å½’ä¸€åŒ–çš„ [-1, 1] æµ®ç‚¹éŸ³é¢‘ä¿å­˜ä¸º 16-bit WAV æ–‡ä»¶"""
        wav = np.clip(wav, -1.0, 1.0)
        scipy.io.wavfile.write(path, sample_rate, (wav * 32767).astype(np.int16))

    def save_wav_norm(wav: np.ndarray, path: str, sample_rate: int = 16000):
        """å…ˆå½’ä¸€åŒ–å†ä¿å­˜ WAVï¼Œé¿å…å‰Šæ³¢"""
        if len(wav) > 0:
            wav = wav / np.max(np.abs(wav)) * 0.95
        save_wav(wav, path, sample_rate)


# ========================
# ğŸ¯ å¤šå…‹éš†éŸ³æ”¯æŒé…ç½®
# ========================
HAS_RESEMBLYZER = False
resemblyzer_encoder = None

# å…‹éš†éŸ³æ³¨å†Œè¡¨ï¼šå­˜å‚¨æ‰€æœ‰å¯ç”¨çš„å…‹éš†éŸ³ä¿¡æ¯
CLONED_VOICES = {}

# å°è¯•åŠ è½½ Resemblyzer


# ========================
# ğŸ¯ Resemblyzer éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥æ¨¡å—
# ========================
try:
    from resemblyzer import VoiceEncoder
    from resemblyzer.audio import preprocess_wav

    # ä½¿ç”¨ Resemblyzer å†…ç½®æ¨¡å‹ï¼Œé¿å…ä¾èµ– pyannote/embedding
    logger.info("âœ… æ­£åœ¨åŠ è½½ Resemblyzer VoiceEncoder...")
    resemblyzer_encoder = VoiceEncoder("cpu")  # å¯æ”¹ä¸º "cuda" å¯ç”¨ GPU
    logger.info("âœ… Resemblyzer VoiceEncoder åŠ è½½æˆåŠŸ")
    
    HAS_RESEMBLYZER = True
    logger.info("âœ… å£°çº¹ä¸€è‡´æ€§æ£€æŸ¥å·²å¯ç”¨ï¼ˆä½¿ç”¨ Resemblyzerï¼‰")
except Exception as e:
    logger.warning(f"âš ï¸ Resemblyzer åŠ è½½å¤±è´¥ï¼ˆå°†è·³è¿‡éŸ³è‰²æ£€æŸ¥ï¼‰: {e}")
    import traceback
    logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
    HAS_RESEMBLYZER = False


# ========================
# ğŸ¯ å…‹éš†éŸ³ç®¡ç†å‡½æ•°
# ========================
def load_cloned_voices():
    """
    åŠ è½½æ‰€æœ‰å…‹éš†éŸ³æ–‡ä»¶ï¼Œæå–å£°çº¹åµŒå…¥
    """
    global CLONED_VOICES
    
    # éå† voice ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    voice_dir = "voice"
    if not os.path.exists(voice_dir):
        logger.error(f"âŒ å…‹éš†éŸ³ç›®å½•ä¸å­˜åœ¨: {voice_dir}")
        return False
    
    # æŸ¥æ‰¾æ‰€æœ‰å…‹éš†éŸ³å¯¹ (.wav + .txt)
    wav_files = [f for f in os.listdir(voice_dir) if f.endswith("_cloned.wav")]
    
    for wav_file in wav_files:
        base_name = os.path.splitext(wav_file)[0].replace("_cloned", "")
        txt_file = f"{base_name}_cloned.txt"
        txt_path = os.path.join(voice_dir, txt_file)
        
        if not os.path.exists(txt_path):
            logger.warning(f"âš ï¸ å…‹éš†éŸ³æ–‡æœ¬ç¼ºå¤±ï¼Œè·³è¿‡: {base_name}")
            continue
        
        # è¯»å–å…‹éš†æ–‡æœ¬
        with open(txt_path, 'r', encoding='utf-8') as f:
            prompt_text = f.read().strip()
        
        if not prompt_text:
            logger.warning(f"âš ï¸ å…‹éš†éŸ³æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡: {base_name}")
            continue
        
        # æ„å»ºå…‹éš†éŸ³ä¿¡æ¯
        voice_info = {
            "name": base_name,
            "wav_path": os.path.join(voice_dir, wav_file),
            "txt_path": txt_path,
            "prompt_text": prompt_text,
            "embedding": None
        }
        
        # æå–å£°çº¹åµŒå…¥
        if HAS_RESEMBLYZER:
            try:
                ref_wav = preprocess_wav(voice_info["wav_path"])
                embedding = resemblyzer_encoder.embed_utterance(ref_wav)
                voice_info["embedding"] = embedding
                logger.info(f"âœ… æå–å…‹éš†éŸ³å£°çº¹: {base_name} (æ—¶é•¿: {len(ref_wav)/16000:.2f}s)")
            except Exception as e:
                logger.warning(f"âš ï¸ æå–å£°çº¹å¤±è´¥ï¼Œè·³è¿‡: {base_name} - {e}")
                continue
        
        CLONED_VOICES[base_name] = voice_info
    
    if CLONED_VOICES:
        logger.info(f"ğŸ¤ åŠ è½½å®Œæˆ {len(CLONED_VOICES)} ä¸ªå…‹éš†éŸ³")
        for name in CLONED_VOICES:
            logger.info(f"   - {name}")
        return True
    else:
        logger.error("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„å…‹éš†éŸ³")
        return False


# åŠ è½½æ‰€æœ‰å…‹éš†éŸ³
if not load_cloned_voices():
    logger.error("âŒ å…‹éš†éŸ³åŠ è½½å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
    sys.exit(1)


# é»˜è®¤å…‹éš†éŸ³ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªåŠ è½½çš„å…‹éš†éŸ³ï¼‰
default_voice_name = next(iter(CLONED_VOICES.keys()))
DEFAULT_VOICE = CLONED_VOICES[default_voice_name]
logger.info(f"ğŸ¤ é»˜è®¤å…‹éš†éŸ³å·²è®¾ç½®: {default_voice_name}")


def find_best_matching_voice(target_wav_path, threshold: float = 0.5) -> dict:
    """
    ä¸ºç›®æ ‡éŸ³é¢‘æ‰¾åˆ°æœ€åŒ¹é…çš„å…‹éš†éŸ³
    
    å‚æ•°:
        target_wav_path (str): ç›®æ ‡éŸ³é¢‘è·¯å¾„
        threshold (float): ç›¸ä¼¼åº¦é˜ˆå€¼
    
    è¿”å›:
        dict: æœ€åŒ¹é…çš„å…‹éš†éŸ³ä¿¡æ¯ï¼Œè‹¥æ²¡æœ‰åŒ¹é…åˆ™è¿”å›é»˜è®¤å…‹éš†éŸ³
    """
    if not HAS_RESEMBLYZER:
        return DEFAULT_VOICE
    
    try:
        # æå–ç›®æ ‡éŸ³é¢‘çš„å£°çº¹
        target_wav = preprocess_wav(target_wav_path)
        if len(target_wav) < 0.5 * 16000:  # å°‘äº 0.5 ç§’ï¼Œä½¿ç”¨é»˜è®¤
            return DEFAULT_VOICE
        
        target_embedding = resemblyzer_encoder.embed_utterance(target_wav)
        
        # è®¡ç®—ä¸æ‰€æœ‰å…‹éš†éŸ³çš„ç›¸ä¼¼åº¦
        best_similarity = -1
        best_voice = DEFAULT_VOICE
        
        for voice_info in CLONED_VOICES.values():
            if voice_info["embedding"] is None:
                continue
            
            similarity = float(np.dot(target_embedding, voice_info["embedding"]))
            logger.debug(f"   ğŸ” å…‹éš†éŸ³ {voice_info['name']} ç›¸ä¼¼åº¦: {similarity:.3f}")
            
            if similarity > best_similarity:
                best_similarity = similarity
                best_voice = voice_info
        
        logger.info(f"ğŸ¯ æœ€ä½³åŒ¹é…å…‹éš†éŸ³: {best_voice['name']} (ç›¸ä¼¼åº¦: {best_similarity:.3f})")
        return best_voice
        
    except Exception as e:
        logger.warning(f"âš ï¸ åŒ¹é…å…‹éš†éŸ³å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: {e}")
        return DEFAULT_VOICE


def is_voice_consistent(generated_wav_path: str, reference_embedding, threshold: float = 0.6) -> bool:
    """
    åˆ¤æ–­ç”Ÿæˆçš„è¯­éŸ³ç‰‡æ®µä¸å‚è€ƒè¯­éŸ³çš„éŸ³è‰²æ˜¯å¦ä¸€è‡´ã€‚

    å‚æ•°:
        generated_wav_path (str): ç”ŸæˆéŸ³é¢‘çš„è·¯å¾„ã€‚
        reference_embedding: å‚è€ƒè¯­éŸ³çš„å£°çº¹åµŒå…¥
        threshold (float): ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ŒèŒƒå›´ [0,1]ï¼Œé»˜è®¤ 0.6ã€‚

    è¿”å›:
        bool: True è¡¨ç¤ºéŸ³è‰²ä¸€è‡´ï¼ˆæˆ–æ— æ³•æ£€æŸ¥æ—¶å®¹é”™é€šè¿‡ï¼‰ï¼ŒFalse è¡¨ç¤ºä¸ä¸€è‡´ã€‚
    """
    if not HAS_RESEMBLYZER or reference_embedding is None:
        return True  # æ— æ³•æ£€æŸ¥æ—¶è§†ä¸ºé€šè¿‡

    try:
        gen_wav = preprocess_wav(generated_wav_path)
        if len(gen_wav) < 0.5 * 16000:  # å°‘äº 0.5 ç§’ï¼Œè·³è¿‡æ£€æŸ¥
            return True
        gen_embedding = resemblyzer_encoder.embed_utterance(gen_wav)
        similarity = float(np.dot(reference_embedding, gen_embedding))
        logger.debug(f"   ğŸ” éŸ³è‰²ç›¸ä¼¼åº¦: {similarity:.3f} (é˜ˆå€¼={threshold})")
        return similarity >= threshold
    except Exception as e:
        logger.warning(f"   âš ï¸ éŸ³è‰²ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
        return True  # å®¹é”™å¤„ç†ï¼šæ£€æŸ¥å¤±è´¥ä¹Ÿè§†ä¸ºé€šè¿‡


# ========================
# ğŸ¯ VoxCPM TTS æ¨¡å‹åŠ è½½
# ========================
VOXCPM_MODEL = None
HAS_VOXCPM = False

def release_voxcpm_model():
    """é‡Šæ”¾ VoxCPM æ¨¡å‹å’ŒGPUèµ„æº"""
    global VOXCPM_MODEL, HAS_VOXCPM, resemblyzer_encoder
    
    logger.info("ğŸ—‘ï¸  æ­£åœ¨é‡Šæ”¾ VoxCPM æ¨¡å‹èµ„æº...")
    
    # é‡Šæ”¾æ¨¡å‹å¼•ç”¨
    VOXCPM_MODEL = None
    HAS_VOXCPM = False
    resemblyzer_encoder = None
    
    # æ¸…ç†GPUç¼“å­˜
    import torch
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    import gc
    gc.collect()
    
    logger.info("âœ… VoxCPM æ¨¡å‹èµ„æºå·²é‡Šæ”¾")

try:
    # æ£€æŸ¥voxcpmæ¨¡å—æ˜¯å¦å®‰è£…
    import importlib.util
    spec = importlib.util.find_spec('voxcpm')
    if spec is None:
        raise ImportError("voxcpmæ¨¡å—æœªå®‰è£…")
    
    from voxcpm import VoxCPM
    logger.info("âœ… æ­£åœ¨åŠ è½½ VoxCPM æ¨¡å‹...")
    
    # å°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨åœ¨çº¿æ¨¡å‹
    try:
        VOXCPM_MODEL = VoxCPM.from_pretrained("openbmb/VoxCPM-0.5B")
        logger.info("âœ… VoxCPM æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        HAS_VOXCPM = True
    except Exception as e:
        logger.warning(f"âš ï¸ åœ¨çº¿åŠ è½½å¤±è´¥: {e}")
        
        # å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
        local_model_path = "models/VoxCPM-0.5B"
        if os.path.exists(local_model_path):
            logger.info(f"âœ… å°è¯•ä»æœ¬åœ°åŠ è½½æ¨¡å‹: {local_model_path}")
            VOXCPM_MODEL = VoxCPM.from_pretrained(local_model_path)
            logger.info("âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            HAS_VOXCPM = True
        else:
            logger.error(f"âŒ æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {local_model_path}")
            raise e
except Exception as e:
    logger.error(f"âŒ VoxCPM æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    import traceback
    logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
    HAS_VOXCPM = False


# ========================
# ğŸ¯ å¯é€‰åŠŸèƒ½ï¼šæ–‡æœ¬è§„èŒƒåŒ– & éŸ³é¢‘æ‹‰ä¼¸
# ========================
HAS_TEXTNORM = False
try:
    from youdub.cn_tx import TextNorm
    normalizer = TextNorm()
    HAS_TEXTNORM = True
except ImportError:
    logger.warning("âš ï¸ æ–‡æœ¬è§„èŒƒåŒ–æ¨¡å—æœªæ‰¾åˆ°")

HAS_AUDIOSTRETCHY = False
try:
    from audiostretchy.stretch import stretch_audio
    HAS_AUDIOSTRETCHY = True
except ImportError:
    logger.warning("âš ï¸ audiostretchyæœªå®‰è£…ï¼Œå°†ä½¿ç”¨librosa")


@dataclass
class TTSConfig:
    """TTS åˆæˆé…ç½®å‚æ•°"""
    sample_rate: int = 16000


def stretch_audio_librosa(wav_path: str, target_path: str, ratio: float, sample_rate: int = 16000) -> bool:
    """
    ä½¿ç”¨ librosa å®ç°éŸ³é¢‘æ—¶é—´æ‹‰ä¼¸ï¼ˆä»…ç”¨äºå‹ç¼©ï¼Œratio < 1.0ï¼‰ã€‚

    å‚æ•°:
        wav_path (str): è¾“å…¥éŸ³é¢‘è·¯å¾„ã€‚
        target_path (str): è¾“å‡ºéŸ³é¢‘è·¯å¾„ã€‚
        ratio (float): æ‹‰ä¼¸æ¯”ä¾‹ï¼ˆ<1 ä¸ºåŠ é€Ÿï¼Œ>1 ä¸ºå‡é€Ÿï¼‰ã€‚
        sample_rate (int): é‡‡æ ·ç‡ã€‚

    è¿”å›:
        bool: æ˜¯å¦æˆåŠŸã€‚
    """
    try:
        wav, sr = librosa.load(wav_path, sr=sample_rate)
        wav_stretched = librosa.effects.time_stretch(wav, rate=ratio)
        import soundfile as sf
        sf.write(target_path, wav_stretched, sr)
        return True
    except Exception as e:
        logger.error(f"librosaæ—¶é—´æ‹‰ä¼¸å¤±è´¥: {e}")
        return False


def adjust_audio_length(wav_path: str, desired_length: float, sample_rate: int = 16000) -> Tuple[np.ndarray, float]:
    """
    è°ƒæ•´éŸ³é¢‘é•¿åº¦ï¼šæ™ºèƒ½åŒ¹é…ç›®æ ‡æ—¶é•¿ï¼Œæ”¯æŒå‹ç¼©å’Œæ‹‰ä¼¸ï¼ˆå¸¦è´¨é‡æ§åˆ¶ï¼‰ã€‚

    å‚æ•°:
        wav_path (str): è¾“å…¥éŸ³é¢‘è·¯å¾„ã€‚
        desired_length (float): ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰ã€‚
        sample_rate (int): é‡‡æ ·ç‡ã€‚

    è¿”å›:
        Tuple[np.ndarray, float]: (è°ƒæ•´åçš„éŸ³é¢‘æ•°ç»„, å®é™…æ—¶é•¿)
    """
    try:
        wav, sr = librosa.load(wav_path, sr=sample_rate)
        current_length = len(wav) / sample_rate

        if current_length <= 0:
            logger.error(f"éŸ³é¢‘é•¿åº¦ä¸º0: {wav_path}")
            return np.zeros(int(desired_length * sample_rate)), desired_length

        # è®¡ç®—æ—¶é•¿å·®å¼‚
        duration_diff = abs(desired_length - current_length)
        # å·®å¼‚å°äº0.5ç§’æ—¶ï¼Œä¸è¿›è¡Œè°ƒæ•´ï¼ˆé¿å…ä¸å¿…è¦çš„å¤„ç†ï¼‰
        if duration_diff < 0.5:
            return wav, current_length

        # è®¡ç®—é€Ÿåº¦å› å­
        speed_factor = current_length / desired_length
        
        # è´¨é‡æ§åˆ¶ï¼šé™åˆ¶æ‹‰ä¼¸/å‹ç¼©æ¯”ä¾‹èŒƒå›´ï¼ˆ0.75-1.25ï¼‰
        # è¶…å‡ºè¿™ä¸ªèŒƒå›´å¯èƒ½å¯¼è‡´éŸ³é¢‘è´¨é‡ä¸¥é‡ä¸‹é™
        speed_factor = max(0.75, min(1.25, speed_factor))
        
        # è®¡ç®—è°ƒæ•´åçš„ç›®æ ‡æ—¶é•¿
        adjusted_length = current_length / speed_factor
        
        logger.info(f"â±ï¸ éŸ³é¢‘é•¿åº¦è°ƒæ•´: {current_length:.2f}s â†’ {adjusted_length:.2f}s (å› å­={speed_factor:.2f})")

        target_path = wav_path.replace('.wav', '_adjusted_temp.wav')
        success = False

        if HAS_AUDIOSTRETCHY:
            try:
                stretch_audio(wav_path, target_path, ratio=speed_factor, sample_rate=sample_rate)
                success = True
            except Exception as e:
                logger.debug(f"audiostretchyå¤±è´¥: {e}")

        if not success:
            if not stretch_audio_librosa(wav_path, target_path, speed_factor, sample_rate):
                return wav, current_length

        if os.path.exists(target_path):
            wav_adjusted, _ = librosa.load(target_path, sr=sample_rate)
            actual_len = len(wav_adjusted) / sample_rate
            os.remove(target_path)
            return wav_adjusted, actual_len

        return wav, current_length

    except Exception as e:
        logger.error(f"éŸ³é¢‘é•¿åº¦è°ƒæ•´å¤±è´¥: {e}")
        return np.zeros(int(desired_length * sample_rate)), desired_length


def generate_voxcpm_audio(text: str, output_path: str, speaker_wav: Optional[str],
                          target_duration: Optional[float] = None, prompt_text: str = None) -> bool:
    """
    ä½¿ç”¨ VoxCPM æ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚

    å‚æ•°:
        text (str): å¾…åˆæˆçš„ä¸­æ–‡æ–‡æœ¬ã€‚
        output_path (str): è¾“å‡ºéŸ³é¢‘è·¯å¾„ã€‚
        speaker_wav (str or None): å‚è€ƒè¯­éŸ³è·¯å¾„ã€‚
        target_duration (float or None): ç›®æ ‡æ—¶é•¿ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼Œä¸å½±å“ç”Ÿæˆï¼‰ã€‚
        prompt_text (str or None): å‚è€ƒæ–‡æœ¬ï¼Œç”¨äºæŒ‡å¯¼éŸ³è‰²å’Œé£æ ¼ã€‚

    è¿”å›:
        bool: æ˜¯å¦æˆåŠŸç”Ÿæˆã€‚
    """
    global VOXCPM_MODEL

    if not HAS_VOXCPM or VOXCPM_MODEL is None:
        logger.error("âŒ VoxCPM æ¨¡å‹ä¸å¯ç”¨")
        return False

    if os.path.exists(output_path):
        return True

    try:
        wav = VOXCPM_MODEL.generate(
            text=text,
            prompt_wav_path=speaker_wav,
            prompt_text=prompt_text,  # ä½¿ç”¨ä¼ å…¥çš„å‚è€ƒæ–‡æœ¬
            cfg_value=2.0,
            inference_timesteps=10,
            normalize=True,
            denoise=False,  # ç¦ç”¨ denoiser ä»¥é¿å…å´©æºƒ
        )
        if not isinstance(wav, np.ndarray):
            wav = np.array(wav, dtype=np.float32)
        import soundfile as sf
        sf.write(output_path, wav, 16000)
        return True
    except Exception as e:
        logger.error(f"VoxCPM ç”Ÿæˆå¤±è´¥: {e}")
        return False


def split_long_sentence(text: str, max_length: int = 30) -> List[str]:
    """
    å°†é•¿å¥å­åˆ†å‰²æˆå¤šä¸ªçŸ­å¥ï¼ŒåŸºäºæ ‡ç‚¹ç¬¦å·ã€‚
    
    å‚æ•°:
        text (str): åŸå§‹é•¿å¥å­
        max_length (int): å•ä¸ªçŸ­å¥çš„æœ€å¤§é•¿åº¦
        
    è¿”å›:
        List[str]: åˆ†å‰²åçš„çŸ­å¥åˆ—è¡¨
    """
    if not text:
        return []
    
    # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²å¥å­
    sentences = []
    current_sentence = ""
    
    # ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
    punctuation = ['ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ã€', ',', '.', '!', '?', ';']
    
    for char in text:
        current_sentence += char
        if char in punctuation and len(current_sentence) > max_length:
            sentences.append(current_sentence.strip())
            current_sentence = ""
    
    if current_sentence.strip():
        sentences.append(current_sentence.strip())
    
    # å¦‚æœåˆ†å‰²åçš„å¥å­ä»ç„¶è¿‡é•¿ï¼Œå°è¯•æŒ‰é•¿åº¦å¼ºåˆ¶åˆ†å‰²
    final_sentences = []
    for sent in sentences:
        if len(sent) > max_length * 1.5:
            # æŒ‰ç©ºæ ¼åˆ†å‰²æˆè¯è¯­
            words = sent.split()
            temp_sent = ""
            for word in words:
                if len(temp_sent) + len(word) + 1 > max_length:
                    final_sentences.append(temp_sent.strip())
                    temp_sent = word
                else:
                    temp_sent = f"{temp_sent} {word}" if temp_sent else word
            if temp_sent.strip():
                final_sentences.append(temp_sent.strip())
        else:
            final_sentences.append(sent)
    
    return final_sentences


def preprocess_text(text: str) -> str:
    """
    å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œæå‡ TTS åˆæˆè´¨é‡ã€‚

    å¤„ç†å†…å®¹ï¼š
    - ç¼©å†™å±•å¼€ï¼ˆå¦‚ AI â†’ äººå·¥æ™ºèƒ½ï¼‰
    - å¤§å†™å­—æ¯åˆ†éš”ï¼ˆå¦‚ "HelloWorld" â†’ "Hello World"ï¼‰
    - æ•°å­—ä¸å­—æ¯é—´åŠ ç©ºæ ¼
    - æ–‡æœ¬è§„èŒƒåŒ–ï¼ˆè‹¥æ¨¡å—å¯ç”¨ï¼‰

    å‚æ•°:
        text (str): åŸå§‹æ–‡æœ¬ã€‚

    è¿”å›:
        str: é¢„å¤„ç†åçš„æ–‡æœ¬ã€‚
    """
    if not text:
        return ""
    text = text.strip()
    replacements = {
        'AI': 'äººå·¥æ™ºèƒ½', 'GPT': 'G P T', 'API': 'A P I', 'UI': 'U I', 'UX': 'U X',
        'CEO': 'C E O', 'CPU': 'C P U', 'GPU': 'G P U'
    }
    for k, v in replacements.items():
        text = text.replace(k, v)
    # åœ¨å¤§å†™å­—æ¯å‰åŠ ç©ºæ ¼ï¼ˆé™¤äº†å¼€å¤´ï¼‰
    text = re.sub(r'(?<!^)([A-Z])', r' \1', text)
    if HAS_TEXTNORM:
        try:
            text = normalizer(text)
        except Exception:
            pass
    # æ•°å­—ä¸å­—æ¯ä¹‹é—´åŠ ç©ºæ ¼
    text = re.sub(r'(?<=[a-zA-Z])(?=\d)|(?<=\d)(?=[a-zA-Z])', ' ', text)
    return re.sub(r'\s+', ' ', text).strip()


def generate_wavs(folder: str, config: Optional[TTSConfig] = None) -> bool:
    """
    ä¸ºå•ä¸ªè§†é¢‘æ–‡ä»¶å¤¹ç”Ÿæˆ TTS éŸ³é¢‘å¹¶æ··åˆä¼´å¥ã€‚

    ç›®å½•ç»“æ„è¦æ±‚ï¼š
    - folder/
        - translation.json       â† å¿…é¡»ï¼šå« 'translation', 'start', 'end'
        - audio_vocals.wav       â† å¯é€‰ï¼šåŸå§‹äººå£°ï¼ˆç”¨äºå¯¹é½æ€»æ—¶é•¿ï¼‰
        - audio_instruments.wav  â† å¯é€‰ï¼šä¼´å¥ï¼ˆç”¨äºæ··åˆï¼‰

    ç”Ÿæˆæ–‡ä»¶ï¼š
    - wavs/0000.wav ...        â† æ¯ä¸ªç‰‡æ®µ
    - audio_tts.wav            â† çº¯ä¸­æ–‡é…éŸ³
    - audio_combined.wav       â† é…éŸ³ + ä¼´å¥ï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰

    å‚æ•°:
        folder (str): è§†é¢‘å¤„ç†ç›®å½•ã€‚
        config (TTSConfig): TTS é…ç½®ã€‚

    è¿”å›:
        bool: æ˜¯å¦æˆåŠŸç”Ÿæˆ combined éŸ³é¢‘ã€‚
    """
    if config is None:
        config = TTSConfig()

    folder_name = os.path.basename(folder)
    logger.info(f"\nğŸ¬ æ­£åœ¨å¤„ç†è§†é¢‘: {folder_name}")

    transcript_path = os.path.join(folder, 'translation.json')
    output_folder = os.path.join(folder, 'wavs')
    combined_path = os.path.join(folder, 'audio_combined.wav')

    if not os.path.exists(transcript_path):
        logger.error(f"âŒ ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {transcript_path}")
        return False
    if os.path.exists(combined_path):
        logger.info(f"â­ï¸ å·²å­˜åœ¨ï¼Œè·³è¿‡: {folder_name}")
        return True
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    with open(transcript_path, 'r', encoding='utf-8') as f:
        transcript = json.load(f)
    if not transcript:
        logger.error(f"âŒ ç¿»è¯‘æ–‡ä»¶ä¸ºç©º")
        return False

    audio_vocals_path = os.path.join(folder, 'audio_vocals.wav')
    original_audio_duration = librosa.get_duration(path=audio_vocals_path) if os.path.exists(audio_vocals_path) else max(line.get('end', 0) for line in transcript)
    logger.info(f"â±ï¸ åŸå§‹éŸ³é¢‘æ€»æ—¶é•¿: {original_audio_duration:.2f}ç§’")

    full_wav = np.zeros(0, dtype=np.float32)

    for i, line in enumerate(transcript):
        text = line.get('translation', '').strip()
        if not text:
            continue

        speaker = line.get('speaker', 'SPEAKER_00')
        processed_text = preprocess_text(text)

        logger.info(f"\nğŸ—£ï¸ ç‰‡æ®µ [{i+1}/{len(transcript)}] | è¯´è¯äºº: {speaker}")
        logger.info(f"ğŸ”¤ åˆæˆæ–‡æœ¬: {processed_text[:45]}{'...' if len(processed_text) > 45 else ''}")

        # æŸ¥æ‰¾è¯´è¯äººçš„å‚è€ƒéŸ³é¢‘ç‰‡æ®µ
        speaker_audio_path = None
        speaker_folder = os.path.join(folder, 'SPEAKER')
        if os.path.exists(speaker_folder):
            speaker_file = os.path.join(speaker_folder, f'{speaker}.wav')
            if os.path.exists(speaker_file):
                speaker_audio_path = speaker_file
        
        # ä¸ºè¯´è¯äººæ‰¾åˆ°æœ€ä½³åŒ¹é…çš„å…‹éš†éŸ³
        if speaker_audio_path:
            best_voice = find_best_matching_voice(speaker_audio_path)
        else:
            best_voice = DEFAULT_VOICE
        
        speaker_wav = best_voice['wav_path']
        speaker_name = best_voice['name']
        logger.info(f"ğŸ¤ ä¸ºè¯´è¯äºº {speaker} åŒ¹é…åˆ°æœ€ä½³å…‹éš†éŸ³: {speaker_name}")

        # è®¡ç®—ç›®æ ‡æ—¶é•¿ï¼ˆä¼˜å…ˆä½¿ç”¨ VAD æ—¶é•¿ï¼Œå¦åˆ™ç”¨åŸå§‹ç‰‡æ®µæ—¶é•¿ï¼‰
        start = float(line.get('start', 0))
        end = float(line.get('end', 0))
        raw_duration = end - start
        vad_duration = line.get('vad_duration')
        target_duration = min(float(vad_duration), raw_duration) if vad_duration else raw_duration
        logger.info(f"â±ï¸ åŸè§†é¢‘æ—¶é•¿: {raw_duration:.2f}s")

        # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦è¿‡é•¿ï¼Œå¦‚æœè¿‡é•¿åˆ™åˆ†å‰²æˆå¤šä¸ªçŸ­å¥
        sentences = split_long_sentence(processed_text, max_length=30)
        
        # ç”ŸæˆéŸ³é¢‘ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        output_path = os.path.join(output_folder, f'{str(i).zfill(4)}.wav')
        success = False
        max_retries = 2

        for attempt in range(max_retries + 1):
            if attempt > 0:
                logger.warning(f"   ğŸ” ç¬¬ {attempt} æ¬¡é‡è¯•ç”Ÿæˆï¼ˆéŸ³è‰²ä¸ä¸€è‡´ï¼‰")

            # å¦‚æœæ˜¯é•¿å¥å­ï¼Œåˆ†å‰²ç”Ÿæˆåæ‹¼æ¥
            if len(sentences) > 1:
                logger.info(f"   ğŸ“ é•¿å¥å­åˆ†å‰²: {len(processed_text)}å­—ç¬¦ â†’ {len(sentences)}ä¸ªçŸ­å¥")
                
                # ä¸ºæ¯ä¸ªçŸ­å¥ç”ŸæˆéŸ³é¢‘
                temp_files = []
                all_wavs = []
                
                for j, short_text in enumerate(sentences):
                            temp_path = os.path.join(output_folder, f'{str(i).zfill(4)}_part{j}.wav')
                            if generate_voxcpm_audio(short_text, temp_path, speaker_wav, target_duration/len(sentences), best_voice['prompt_text']):
                                temp_files.append(temp_path)
                                wav, sr = librosa.load(temp_path, sr=config.sample_rate)
                                all_wavs.append(wav)
                            else:
                                logger.error(f"   âŒ çŸ­å¥ {j+1} ç”Ÿæˆå¤±è´¥")
                                break
                
                if len(all_wavs) == len(sentences):
                    # æ‹¼æ¥æ‰€æœ‰çŸ­å¥éŸ³é¢‘
                    combined_wav = np.concatenate(all_wavs)
                    # ä¿å­˜æ‹¼æ¥åçš„éŸ³é¢‘
                    import soundfile as sf
                    sf.write(output_path, combined_wav, config.sample_rate)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    for temp_file in temp_files:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    
                    # æ£€æŸ¥éŸ³è‰²ä¸€è‡´æ€§
                    if is_voice_consistent(output_path, best_voice['embedding'], threshold=0.6):
                        success = True
                        break
                    else:
                        logger.warning("   âŒ éŸ³è‰²ä¸ä¸€è‡´ï¼Œå°†é‡è¯•...")
                        if os.path.exists(output_path):
                            os.remove(output_path)
                else:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    for temp_file in temp_files:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    break
            else:
                # æ™®é€šçŸ­å¥ç›´æ¥ç”Ÿæˆ
                if generate_voxcpm_audio(processed_text, output_path, speaker_wav, target_duration, best_voice['prompt_text']):
                    if is_voice_consistent(output_path, best_voice['embedding'], threshold=0.6):
                        success = True
                        break
                    else:
                        logger.warning("   âŒ éŸ³è‰²ä¸ä¸€è‡´ï¼Œå°†é‡è¯•...")
                        if os.path.exists(output_path):
                            os.remove(output_path)
                else:
                    break  # ç”Ÿæˆå¤±è´¥ä¸å†é‡è¯•

        if not success:
            logger.error(f"âŒ ç‰‡æ®µ {i+1} ç”Ÿæˆå¤±è´¥æˆ–éŸ³è‰²ä¸ä¸€è‡´ï¼Œè·³è¿‡")
            continue

        # éŸ³é¢‘åå¤„ç†ï¼šå¯¹é½æ—¶é—´è½´
        try:
            gen_wav, sr = librosa.load(output_path, sr=config.sample_rate)
            gen_duration = len(gen_wav) / sr
            logger.info(f"   ğŸ™ï¸ TTSç”Ÿæˆæ—¶é•¿: {gen_duration:.2f}s")

            wav_adjusted, final_duration = adjust_audio_length(output_path, target_duration, config.sample_rate)
            logger.info(f"   ğŸ“ æœ€ç»ˆéŸ³é¢‘æ—¶é•¿: {final_duration:.2f}s")

            # æ’å…¥é™éŸ³å¯¹é½èµ·å§‹æ—¶é—´
            current_time = len(full_wav) / config.sample_rate
            if start > current_time:
                silence_samples = int((start - current_time) * config.sample_rate)
                if silence_samples > 0:
                    full_wav = np.concatenate([full_wav, np.zeros(silence_samples, dtype=np.float32)])
            elif start < current_time:
                target_samples = int(start * config.sample_rate)
                if target_samples < len(full_wav):
                    full_wav = full_wav[:target_samples]

            # é™åˆ¶ç»“æŸæ—¶é—´ï¼ˆé¿å…ç‰‡æ®µé‡å ï¼‰
            max_end_samples = int((end + 0.2) * config.sample_rate)
            current_samples = len(full_wav)
            if current_samples + len(wav_adjusted) > max_end_samples:
                allowed = max_end_samples - current_samples
                if allowed > 0:
                    wav_adjusted = wav_adjusted[:allowed]
                else:
                    wav_adjusted = np.zeros(0)

            if len(wav_adjusted) > 0:
                full_wav = np.concatenate([full_wav, wav_adjusted])

        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç‰‡æ®µ {i+1} å¤±è´¥: {e}")
            traceback.print_exc()
            continue

    # ä¿å­˜æœ€ç»ˆ TTS éŸ³é¢‘
    if len(full_wav) == 0:
        return False

    target_samples = int(original_audio_duration * config.sample_rate)
    if len(full_wav) < target_samples:
        full_wav = np.pad(full_wav, (0, target_samples - len(full_wav)), mode='constant')
    elif len(full_wav) > target_samples:
        full_wav = full_wav[:target_samples]

    # éŸ³é‡å¯¹é½ï¼ˆå‚è€ƒåŸäººå£°éŸ³é‡ï¼‰
    if os.path.exists(audio_vocals_path):
        try:
            vocal_wav, sr = librosa.load(audio_vocals_path, sr=config.sample_rate)
            if len(vocal_wav) > 0 and np.max(np.abs(full_wav)) > 0:
                full_wav = full_wav / np.max(np.abs(full_wav)) * np.max(np.abs(vocal_wav)) * 0.95
        except Exception as e:
            logger.warning(f"éŸ³é‡å¯¹é½å¤±è´¥: {e}")

    tts_path = os.path.join(folder, 'audio_tts.wav')
    save_wav(full_wav, tts_path, config.sample_rate)
    logger.info(f"ğŸ”Š TTSéŸ³é¢‘å·²ä¿å­˜: {tts_path}")

    # æ··åˆä¼´å¥
    instruments_path = os.path.join(folder, 'audio_instruments.wav')
    if os.path.exists(instruments_path):
        try:
            inst_wav, sr = librosa.load(instruments_path, sr=config.sample_rate)
            if len(full_wav) > len(inst_wav):
                inst_wav = np.pad(inst_wav, (0, len(full_wav) - len(inst_wav)), mode='constant')
            elif len(inst_wav) > len(full_wav):
                full_wav = np.pad(full_wav, (0, len(inst_wav) - len(full_wav)), mode='constant')
            combined = full_wav * 0.8 + inst_wav * 0.6  # é…éŸ³ 80%ï¼Œä¼´å¥ 60%
            combined_path = os.path.join(folder, 'audio_combined.wav')
            save_wav_norm(combined, combined_path, config.sample_rate)
            logger.info(f"ğŸ§ æ··åˆéŸ³é¢‘å·²ä¿å­˜: {combined_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ æ··åˆå¤±è´¥: {e}")
            return False
    else:
        logger.warning("âš ï¸ æ— ä¼´å¥æ–‡ä»¶ï¼Œä»…ä¿å­˜ TTS éŸ³é¢‘")
        return True


def generate_all_wavs_under_folder(root_folder: str) -> Dict[str, Any]:
    """
    éå†æ ¹ç›®å½•ï¼Œå¯¹æ‰€æœ‰åŒ…å« translation.json çš„å­æ–‡ä»¶å¤¹æ‰§è¡Œ TTS åˆæˆã€‚

    å‚æ•°:
        root_folder (str): æ ¹ç›®å½•è·¯å¾„ã€‚

    è¿”å›:
        Dict: ç»Ÿè®¡ç»“æœï¼Œå«æˆåŠŸ/å¤±è´¥/è·³è¿‡æ•°é‡ã€‚
    """
    results = {
        'total': 0,
        'processed': 0,
        'success': 0,
        'failed': 0,
        'failed_folders': [],
        'skipped': 0
    }
    for root, _, files in os.walk(root_folder):
        if 'translation.json' in files:
            results['total'] += 1
            if 'audio_combined.wav' in files:
                results['skipped'] += 1
                logger.info(f'â­ï¸ è·³è¿‡: {os.path.basename(root)}')
                continue
            results['processed'] += 1
            if generate_wavs(root):
                results['success'] += 1
            else:
                results['failed'] += 1
                results['failed_folders'].append(root)
    return results


def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å¯åŠ¨å¤„ç†æµç¨‹ã€‚
    
    ç”¨æ³•:
        python script.py --folder <å•ä¸ªè§†é¢‘ç›®å½•>
        python script.py --all [--root <æ ¹ç›®å½•>]
    """
    import argparse
    parser = argparse.ArgumentParser(description="è‹±æ–‡è§†é¢‘è½¬ä¸­æ–‡é…éŸ³ TTS è„šæœ¬")
    parser.add_argument('--folder', type=str, help="å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶å¤¹")
    parser.add_argument('--all', action='store_true', help="å¤„ç†æ ¹ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘")
    parser.add_argument('--root', type=str, default='videos', help="æ‰¹é‡å¤„ç†çš„æ ¹ç›®å½•ï¼ˆé»˜è®¤: videosï¼‰")
    args = parser.parse_args()

    # é…ç½®æ—¥å¿—æ ¼å¼
    logger.remove()
    logger.add(sys.stdout, level="INFO", format="<green>{time:MM-DD HH:mm:ss}</green> | <level>{level: <6}</level> | <cyan>{message}</cyan>")

    if not HAS_VOXCPM:
        logger.error("âŒ VoxCPM ä¸å¯ç”¨")
        sys.exit(1)

    if args.all or (not args.folder and not args.all):
        results = generate_all_wavs_under_folder(args.root if args.all else 'videos')
        logger.info("\n" + "="*50)
        logger.info(f"âœ… æˆåŠŸ: {results['success']}/{results['processed']} | â­ï¸ è·³è¿‡: {results['skipped']}")
        if results['failed'] > 0:
            logger.warning(f"âŒ å¤±è´¥: {results['failed']} ä¸ªè§†é¢‘")
            for f in results['failed_folders']:
                logger.warning(f"   - {f}")
    elif args.folder:
        folder_name = os.path.basename(args.folder)
        if os.path.exists(os.path.join(args.folder, 'audio_combined.wav')):
            logger.info(f"â­ï¸ è·³è¿‡: {folder_name}")
        else:
            logger.info(f"ğŸ¬ å¤„ç†: {folder_name}")
            generate_wavs(args.folder)


if __name__ == '__main__':
    main()