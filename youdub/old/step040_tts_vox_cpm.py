#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯­éŸ³åˆæˆä¸éŸ³é¢‘å¤„ç†è„šæœ¬ - VAD æ—¶é•¿æ„ŸçŸ¥ç‰ˆï¼ˆVoxCPM é›†æˆï¼‰âœ… æœ€ç»ˆç‰ˆ
æ ¸å¿ƒç‰¹æ€§ï¼š
  - âœ… è‹±æ–‡éŸ³è‰² + ä¸­æ–‡è¯­éŸ³åˆæˆï¼ˆè·¨è¯­è¨€å…‹éš†ï¼‰
  - âœ… è‡ªåŠ¨ä¼˜å…ˆä½¿ç”¨ SPEAKER_XX_CLONE.wav / .txt
  - âœ… è‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨ audio_combined.wav çš„è§†é¢‘
  - âœ… ä¿®å¤ VoxCPM prompt_wav + prompt_text è¯­è¨€ä¸€è‡´æ€§
  - âœ… æ— å‚è€ƒæ—¶é™çº§ä¸ºé»˜è®¤å£°éŸ³
  - âœ… ä¿ç•™ VAD æ—¶é•¿æ„ŸçŸ¥ + éŸ³é¢‘æ‹‰ä¼¸
  - âœ… ä¸­æ–‡æ–‡æœ¬é¢„å¤„ç† + ä¼´å¥æ··åˆ

ä½œè€…: Advanced TTS Team
æ—¥æœŸ: 2026-01-04
ç‰ˆæœ¬: 1.8
"""

import json
import os
import re
import librosa
import sys
import traceback
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import numpy as np

from loguru import logger

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
try:
    from youdub.utils import save_wav, save_wav_norm
except ImportError:
    logger.warning("youdub.utils æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°å®ç°")
    import scipy.io.wavfile

    def save_wav(wav: np.ndarray, path: str, sample_rate: int = 16000):
        wav = np.clip(wav, -1.0, 1.0)
        scipy.io.wavfile.write(path, sample_rate, (wav * 32767).astype(np.int16))

    def save_wav_norm(wav: np.ndarray, path: str, sample_rate: int = 16000):
        if len(wav) > 0:
            wav = wav / np.max(np.abs(wav)) * 0.95
        save_wav(wav, path, sample_rate)


# ========================
# ğŸ¯ VoxCPM æ¨¡å‹åŠ è½½
# ========================
VOXCPM_MODEL = None
HAS_VOXCPM = False

try:
    from voxcpm import VoxCPM
    logger.info("âœ… æ­£åœ¨åŠ è½½ VoxCPM æ¨¡å‹...")
    VOXCPM_MODEL = VoxCPM.from_pretrained("openbmb/VoxCPM-0.5B")
    HAS_VOXCPM = True
    logger.info("âœ… VoxCPM æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    logger.error(f"âŒ VoxCPM æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    HAS_VOXCPM = False


# æ–‡æœ¬è§„èŒƒåŒ–
try:
    from youdub.cn_tx import TextNorm
    normalizer = TextNorm()
    HAS_TEXTNORM = True
except ImportError:
    HAS_TEXTNORM = False
    logger.warning("âš ï¸ æ–‡æœ¬è§„èŒƒåŒ–æ¨¡å—æœªæ‰¾åˆ°")


# éŸ³é¢‘æ‹‰ä¼¸
try:
    from audiostretchy.stretch import stretch_audio
    HAS_AUDIOSTRETCHY = True
except ImportError:
    HAS_AUDIOSTRETCHY = False
    logger.warning("âš ï¸ audiostretchyæœªå®‰è£…ï¼Œå°†ä½¿ç”¨librosa")


@dataclass
class TTSConfig:
    sample_rate: int = 16000
    use_voxcpm: bool = True
    min_speed_factor: float = 0.95
    max_speed_factor: float = 1.05


def preprocess_text(text: str) -> str:
    if not text or not isinstance(text, str):
        return ""
    
    text = text.strip()
    
    replacements = {
        'AI': 'äººå·¥æ™ºèƒ½',
        'GPT': 'G P T',
        'API': 'A P I',
        'UI': 'U I',
        'UX': 'U X',
        'CEO': 'C E O',
        'CPU': 'C P U',
        'GPU': 'G P U',
    }
    
    for key, value in replacements.items():
        text = text.replace(key, value)
    
    text = re.sub(r'(?<!^)([A-Z])', r' \1', text)
    
    if HAS_TEXTNORM:
        try:
            text = normalizer(text)
        except Exception:
            logger.warning("æ–‡æœ¬è§„èŒƒåŒ–å¤±è´¥")
    
    text = re.sub(r'(?<=[a-zA-Z])(?=\d)|(?<=\d)(?=[a-zA-Z])', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()


def stretch_audio_librosa(wav_path: str, target_path: str, ratio: float, sample_rate: int = 16000):
    try:
        wav, sr = librosa.load(wav_path, sr=sample_rate)
        wav_stretched = librosa.effects.time_stretch(wav, rate=ratio)
        import soundfile as sf
        sf.write(target_path, wav_stretched, sr)
        return True
    except Exception as e:
        logger.error(f"librosaæ—¶é—´æ‹‰ä¼¸å¤±è´¥: {e}")
        return False


def adjust_audio_length(wav_path: str, desired_length: float,
                        sample_rate: int = 16000,
                        min_speed_factor: float = 0.95,
                        max_speed_factor: float = 1.05) -> Tuple[np.ndarray, float]:
    try:
        wav, sr = librosa.load(wav_path, sr=sample_rate)
        current_length = len(wav) / sample_rate

        if current_length <= 0:
            logger.error(f"éŸ³é¢‘é•¿åº¦ä¸º0: {wav_path}")
            return np.zeros(int(desired_length * sample_rate)), desired_length

        speed_factor = max(
            min(desired_length / current_length, max_speed_factor),
            min_speed_factor
        )

        logger.debug(f"éŸ³é¢‘é•¿åº¦è°ƒæ•´: {current_length:.2f}s -> {desired_length:.2f}s, å› å­: {speed_factor:.3f}")

        target_path = wav_path.replace('.wav', f'_adjusted.wav')

        if HAS_AUDIOSTRETCHY:
            try:
                stretch_audio(wav_path, target_path, ratio=speed_factor, sample_rate=sample_rate)
            except Exception as e:
                logger.warning(f"audiostretchyå¤±è´¥ï¼Œä½¿ç”¨librosa: {e}")
                if not stretch_audio_librosa(wav_path, target_path, speed_factor, sample_rate):
                    target_path = wav_path
        else:
            if not stretch_audio_librosa(wav_path, target_path, speed_factor, sample_rate):
                target_path = wav_path

        wav_adjusted, sr = librosa.load(target_path, sr=sample_rate)

        if target_path != wav_path and os.path.exists(target_path):
            try:
                os.remove(target_path)
            except:
                pass

        return wav_adjusted, current_length * speed_factor

    except Exception as e:
        logger.error(f"éŸ³é¢‘é•¿åº¦è°ƒæ•´å¤±è´¥: {e}")
        return np.zeros(int(desired_length * sample_rate)), desired_length


def generate_voxcpm_audio(text: str, output_path: str, speaker_wav: Optional[str],
                          target_duration: Optional[float] = None) -> bool:
    global VOXCPM_MODEL

    if not HAS_VOXCPM or VOXCPM_MODEL is None:
        logger.error("âŒ VoxCPM æ¨¡å‹ä¸å¯ç”¨")
        return False

    if os.path.exists(output_path):
        logger.info(f"âœ… éŸ³é¢‘å·²å­˜åœ¨: {output_path}")
        return True

    logger.debug(f"ğŸ—£ï¸ VoxCPM ç”Ÿæˆ: \"{text[:50]}...\" (ç›®æ ‡æ—¶é•¿: {target_duration:.2f}s)")

    # === å…³é”®ï¼šå®‰å…¨åŠ è½½å‚è€ƒæ–‡æœ¬ï¼ˆå¿…é¡»ä¸éŸ³é¢‘è¯­è¨€ä¸€è‡´ï¼‰===
    prompt_text = None
    if speaker_wav and os.path.exists(speaker_wav):
        base = os.path.splitext(speaker_wav)[0]
        # ä¼˜å…ˆä½¿ç”¨ _CLONE.txtï¼ˆæ ‡å‡†è¾“å‡ºï¼‰
        candidate_txts = [
            base + "_CLONE.txt",
            base + ".txt"
        ]
        for txt_candidate in candidate_txts:
            if os.path.exists(txt_candidate) and os.path.getsize(txt_candidate) > 0:
                try:
                    with open(txt_candidate, 'r', encoding='utf-8') as f:
                        prompt_text = f.read().strip()
                    if prompt_text:
                        logger.debug(f"ğŸ“œ ä½¿ç”¨å‚è€ƒæ–‡æœ¬: {prompt_text[:40]}...")
                        break  # æ‰¾åˆ°å°±åœæ­¢
                except Exception as e:
                    logger.warning(f"âš ï¸ å‚è€ƒæ–‡æœ¬åŠ è½½å¤±è´¥ ({txt_candidate}): {e}")
        
        if not prompt_text:
            logger.warning(f"âš ï¸ æœ‰å‚è€ƒéŸ³é¢‘ä½†æ— æœ‰æ•ˆæ–‡æœ¬ï¼Œç¦ç”¨è¯­éŸ³å…‹éš†: {speaker_wav}")
            speaker_wav = None
            prompt_text = None
    else:
        speaker_wav = None
        prompt_text = None

    try:
        wav = VOXCPM_MODEL.generate(
            text=text,                    # â† ä¸­æ–‡ï¼ˆç›®æ ‡è¯­è¨€ï¼‰
            prompt_wav_path=speaker_wav,  # â† è‹±æ–‡éŸ³é¢‘ï¼ˆéŸ³è‰²æ¥æºï¼‰
            prompt_text=prompt_text,      # â† è‹±æ–‡åŸæ–‡ï¼ˆå¿…é¡»åŒ¹é…éŸ³é¢‘ï¼‰
            cfg_value=2.0,
            inference_timesteps=10,
            normalize=True,
            denoise=True,
            retry_badcase=True,
            retry_badcase_max_times=3,
            retry_badcase_ratio_threshold=6.0,
        )

        if isinstance(wav, list):
            wav = np.array(wav, dtype=np.float32)
        elif not isinstance(wav, np.ndarray):
            wav = np.array(wav)

        import soundfile as sf
        sf.write(output_path, wav, 16000)
        return True

    except Exception as e:
        logger.error(f"âŒ VoxCPM ç”Ÿæˆå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return False


def generate_tts_audio(text: str, output_path: str, speaker_wav: Optional[str],
                       engine: str, config: TTSConfig, target_duration: float = None) -> bool:
    return generate_voxcpm_audio(text, output_path, speaker_wav, target_duration)


def choose_tts_engine(num_speakers: int, config: TTSConfig) -> str:
    if HAS_VOXCPM:
        return 'voxcpm'
    logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„TTSå¼•æ“")
    return 'none'


def generate_wavs(folder: str, config: Optional[TTSConfig] = None) -> bool:
    if config is None:
        config = TTSConfig()

    transcript_path = os.path.join(folder, 'translation.json')
    output_folder = os.path.join(folder, 'wavs')

    if not os.path.exists(transcript_path):
        logger.error(f"âŒ ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {transcript_path}")
        return False

    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # === è·³è¿‡å·²å­˜åœ¨æœ€ç»ˆè¾“å‡ºçš„è§†é¢‘ ===
    combined_path = os.path.join(folder, 'audio_combined.wav')
    if os.path.exists(combined_path):
        logger.info(f"â­ï¸ æœ€ç»ˆéŸ³é¢‘å·²å­˜åœ¨ï¼Œè·³è¿‡: {folder}")
        return True

    try:
        with open(transcript_path, 'r', encoding='utf-8') as f:
            transcript = json.load(f)

        if not transcript:
            logger.error(f"âŒ ç¿»è¯‘æ–‡ä»¶ä¸ºç©º: {transcript_path}")
            return False

        audio_vocals_path = os.path.join(folder, 'audio_vocals.wav')
        if os.path.exists(audio_vocals_path):
            original_audio_duration = librosa.get_duration(path=audio_vocals_path)
        else:
            original_audio_duration = max(line.get('end', 0) for line in transcript)
        logger.info(f"â±ï¸ åŸå§‹éŸ³é¢‘æ€»æ—¶é•¿: {original_audio_duration:.2f}ç§’")

        speakers = {line.get('speaker', 'SPEAKER_00') for line in transcript}
        num_speakers = len(speakers)
        logger.info(f'ğŸ‘¥ å‘ç° {num_speakers} ä¸ªè¯´è¯äºº: {sorted(speakers)}')

        engine = choose_tts_engine(num_speakers, config)
        if engine == 'none':
            return False
        logger.info(f'ğŸ¤– ä½¿ç”¨TTSå¼•æ“: {engine}')

        full_wav = np.zeros(0, dtype=np.float32)

        for i, line in enumerate(transcript):
            speaker = line.get('speaker', 'SPEAKER_00')
            original_text = line.get('translation', '').strip()  # â† ä¸­æ–‡ï¼

            if not original_text:
                logger.warning(f"âš ï¸ ç¬¬{i}è¡Œæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
                continue

            text = preprocess_text(original_text)
            logger.debug(f"ğŸ”¤ å¤„ç†ç‰‡æ®µ {i}: {text[:50]}...")

            output_path = os.path.join(output_folder, f'{str(i).zfill(4)}.wav')

            # === æŸ¥æ‰¾å‚è€ƒéŸ³é¢‘ï¼ˆä¼˜å…ˆ _CLONE.wavï¼‰===
            speaker_wav = None
            speaker_dir = os.path.join(folder, 'SPEAKER')
            if os.path.exists(speaker_dir):
                candidates = [
                    os.path.join(speaker_dir, f'{speaker}_CLONE.wav'),
                    os.path.join(speaker_dir, f'{speaker}.wav')
                ]
                for cand in candidates:
                    if os.path.exists(cand):
                        speaker_wav = cand
                        break

            original_start = float(line.get('start', 0))
            original_end = float(line.get('end', 0))
            raw_duration = original_end - original_start
            vad_duration = line.get('vad_duration')

            if vad_duration is not None:
                target_duration = min(float(vad_duration), raw_duration)
                logger.debug(f"ğŸ¯ ç‰‡æ®µ {i}: VAD æ—¶é•¿ = {target_duration:.2f}s (åŸå§‹ {raw_duration:.2f}s)")
            else:
                target_duration = raw_duration
                logger.debug(f"ğŸ¯ ç‰‡æ®µ {i}: åŸå§‹æ—¶é•¿ = {target_duration:.2f}s (æ—  VAD æ•°æ®)")

            success = generate_tts_audio(
                text,
                output_path,
                speaker_wav,
                engine,
                config,
                target_duration=target_duration
            )

            if not success:
                logger.error(f"âŒ ç‰‡æ®µ {i} TTSç”Ÿæˆå¤±è´¥")
                silence_duration = line.get('end', 0) - line.get('start', 0)
                if silence_duration > 0:
                    silence_samples = int(silence_duration * config.sample_rate)
                    silence_wav = np.zeros(silence_samples, dtype=np.float32)
                    save_wav(silence_wav, output_path, config.sample_rate)
                else:
                    continue

            current_time = len(full_wav) / config.sample_rate
            if original_start > current_time:
                silence_samples = int((original_start - current_time) * config.sample_rate)
                if silence_samples > 0:
                    full_wav = np.concatenate((full_wav, np.zeros(silence_samples, dtype=np.float32)))
            elif original_start < current_time:
                target_samples = int(original_start * config.sample_rate)
                if target_samples < len(full_wav):
                    full_wav = full_wav[:target_samples]
                current_time = original_start

            wav_adjusted, _ = adjust_audio_length(
                output_path,
                target_duration,
                sample_rate=config.sample_rate,
                min_speed_factor=config.min_speed_factor,
                max_speed_factor=config.max_speed_factor
            )

            overlap_tolerance = 0.15
            max_allowed_samples = int((original_end + overlap_tolerance) * config.sample_rate)
            current_samples = len(full_wav)
            if current_samples + len(wav_adjusted) > max_allowed_samples:
                allowed_length = max_allowed_samples - current_samples
                if allowed_length > 0:
                    wav_adjusted = wav_adjusted[:allowed_length]
                else:
                    wav_adjusted = np.zeros(0)

            if len(wav_adjusted) > 0:
                full_wav = np.concatenate((full_wav, wav_adjusted))
            else:
                logger.warning(f"âš ï¸ ç‰‡æ®µ {i} éŸ³é¢‘ä¸ºç©ºï¼Œè·³è¿‡")

        if len(full_wav) == 0:
            logger.error("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘")
            return False

        target_final_samples = int(original_audio_duration * config.sample_rate)
        if len(full_wav) < target_final_samples:
            full_wav = np.pad(full_wav, (0, target_final_samples - len(full_wav)), mode='constant')
        elif len(full_wav) > target_final_samples:
            full_wav = full_wav[:target_final_samples]

        if os.path.exists(audio_vocals_path):
            try:
                vocal_wav, sr = librosa.load(audio_vocals_path, sr=config.sample_rate)
                if len(vocal_wav) > 0:
                    vocal_max = np.max(np.abs(vocal_wav))
                    if vocal_max > 0 and np.max(np.abs(full_wav)) > 0:
                        full_wav = full_wav / np.max(np.abs(full_wav)) * vocal_max * 0.95
            except Exception as e:
                logger.warning(f"éŸ³é‡å‚è€ƒå¤±è´¥: {e}")

        tts_output_path = os.path.join(folder, 'audio_tts.wav')
        save_wav(full_wav, tts_output_path, config.sample_rate)
        logger.info(f"ğŸ”Š TTSéŸ³é¢‘å·²ä¿å­˜: {tts_output_path}")

        instruments_path = os.path.join(folder, 'audio_instruments.wav')
        if os.path.exists(instruments_path):
            try:
                instruments_wav, sr = librosa.load(instruments_path, sr=config.sample_rate)
                if len(full_wav) > len(instruments_wav):
                    instruments_wav = np.pad(instruments_wav, (0, len(full_wav) - len(instruments_wav)), mode='constant')
                elif len(instruments_wav) > len(full_wav):
                    full_wav = np.pad(full_wav, (0, len(instruments_wav) - len(full_wav)), mode='constant')
                combined_wav = full_wav * 0.8 + instruments_wav * 0.6
                combined_output_path = os.path.join(folder, 'audio_combined.wav')
                save_wav_norm(combined_wav, combined_output_path, config.sample_rate)
                logger.info(f"ğŸ§ æ··åˆéŸ³é¢‘å·²ä¿å­˜: {combined_output_path}")
            except Exception as e:
                logger.error(f"âŒ éŸ³é¢‘æ··åˆå¤±è´¥: {e}")
                return False
        else:
            logger.warning(f"âš ï¸ ä¼´å¥æ–‡ä»¶ä¸å­˜åœ¨: {instruments_path}")

        return True

    except Exception as e:
        logger.error(f"ğŸ’¥ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return False


def generate_all_wavs_under_folder(root_folder: str,
                                   config: Optional[TTSConfig] = None,
                                   skip_existing: bool = True) -> Dict[str, Any]:
    if config is None:
        config = TTSConfig()

    results = {
        'total_folders': 0,
        'processed': 0,
        'success': 0,
        'failed': 0,
        'failed_folders': [],
        'skipped': 0
    }

    for root, dirs, files in os.walk(root_folder):
        if 'translation.json' in files:
            results['total_folders'] += 1

            if 'audio_combined.wav' in files:
                logger.info(f'â­ï¸ è·³è¿‡å·²å¤„ç†: {root}')
                results['skipped'] += 1
                continue

            logger.info(f'ğŸ“ å¤„ç†: {root}')
            results['processed'] += 1

            success = generate_wavs(root, config)
            if success:
                results['success'] += 1
                logger.info(f'âœ… å®Œæˆ: {root}')
            else:
                results['failed'] += 1
                results['failed_folders'].append(root)
                logger.error(f'âŒ å¤±è´¥: {root}')

    return results


def main():
    import argparse

    parser = argparse.ArgumentParser(description='ä½¿ç”¨ VoxCPM çš„è¯­éŸ³åˆæˆè„šæœ¬ï¼ˆâœ… è·¨è¯­è¨€å…‹éš†ç‰ˆï¼‰')
    parser.add_argument('--folder', type=str, help='å¤„ç†å•ä¸ªæ–‡ä»¶å¤¹')
    parser.add_argument('--all', action='store_true', help='æ‰¹é‡å¤„ç†')
    parser.add_argument('--root', type=str, default='videos', help='æ ¹ç›®å½•')
    parser.add_argument('--skip-existing', action='store_true', help='è·³è¿‡å·²å­˜åœ¨')

    args = parser.parse_args()

    config = TTSConfig()

    logger.remove()
    logger.add(sys.stdout, level="INFO",
               format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>")

    if not HAS_VOXCPM:
        logger.error("âŒ VoxCPM æ¨¡å‹ä¸å¯ç”¨ï¼Œé€€å‡º")
        sys.exit(1)

    if args.all or (not args.folder and not args.all):
        root_dir = args.root if args.all else 'videos'
        logger.info(f"ğŸ”„ æ‰¹é‡å¤„ç†æ‰€æœ‰å¾…å¤„ç†è§†é¢‘ï¼ˆæ ¹ç›®å½•: {root_dir})")
        results = generate_all_wavs_under_folder(root_dir, config)

        logger.info("\n" + "=" * 50)
        logger.info("ğŸ“Š å¤„ç†å®Œæˆï¼")
        logger.info(f"æ€»è®¡: {results['total_folders']}")
        logger.info(f"å¤„ç†: {results['processed']}")
        logger.info(f"æˆåŠŸ: {results['success']}")
        logger.info(f"å¤±è´¥: {results['failed']}")
        logger.info(f"è·³è¿‡: {results['skipped']}")

        if results['failed'] > 0:
            logger.warning(f"å¤±è´¥åˆ—è¡¨: {results['failed_folders']}")
    elif args.folder:
        combined_path = os.path.join(args.folder, 'audio_combined.wav')
        if os.path.exists(combined_path):
            logger.info(f"â­ï¸ å•ä¸ªæ–‡ä»¶å¤¹å·²å¤„ç†ï¼Œè·³è¿‡: {args.folder}")
            return
        logger.info(f"ğŸ¬ å¤„ç†å•ä¸ª: {args.folder}")
        success = generate_wavs(args.folder, config)
        if success:
            logger.info("ğŸ‰ å®Œæˆï¼")
        else:
            logger.error("ğŸ’¥ å¤±è´¥ï¼")
    else:
        logger.error("âŒ è¯·æŒ‡å®š --folder æˆ–ä½¿ç”¨é»˜è®¤æ‰¹é‡æ¨¡å¼")


if __name__ == '__main__':
    main()
