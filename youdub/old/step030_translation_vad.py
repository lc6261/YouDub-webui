#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§è§†é¢‘å­—å¹•ç¿»è¯‘æ¨¡å—ï¼ˆQwen2.5 + å¤šè½®æ ¡å¯¹ + æœ¯è¯­åº“ï¼‰

æ”¹è¿›ç‚¹ï¼š
1. ä½¿ç”¨ Qwen2.5-14Bï¼ˆæ˜¾è‘—ä¼˜äº Llama3.1-8Bï¼‰
2. é¢†åŸŸæœ¯è¯­è‡ªåŠ¨æå–ä¸ä¸€è‡´æ€§æ§åˆ¶
3. ä¸¤éç¿»è¯‘ + è´¨é‡æ ¡å¯¹
4. Few-shot ç¤ºä¾‹å­¦ä¹ 
5. å£è¯­åŒ–ä¼˜åŒ–

å®‰è£…ï¼š
ollama pull qwen2.5:14b
# æˆ–ä½¿ç”¨ Qwen2.5-32B: ollama pull qwen2.5:32b

ä½œè€…: Advanced Translation Team
æ—¥æœŸ: 2026-01-03
ç‰ˆæœ¬: 1.0
"""

import json
import os
import re
import sys
import time
from typing import List, Dict, Tuple, Optional
from openai import OpenAI
from loguru import logger
from dotenv import load_dotenv

load_dotenv()

# ===== é…ç½® =====
MODEL_NAME = os.getenv('MODEL_NAME', 'qwen2.5:14b')
API_BASE = os.getenv('OPENAI_API_BASE', 'http://127.0.0.1:11434/v1')
API_KEY = os.getenv('OPENAI_API_KEY', 'ollama')

logger.info(f"ğŸ¤– ä½¿ç”¨ç¿»è¯‘æ¨¡å‹: {MODEL_NAME}")
logger.info(f"ğŸŒ APIåœ°å€: {API_BASE}")

_client: Optional[OpenAI] = None

def get_client() -> OpenAI:
    global _client
    if _client is None:
        _client = OpenAI(base_url=API_BASE, api_key=API_KEY, timeout=120.0)
    return _client


# ===== æœ¯è¯­æå–ä¸ç®¡ç† =====
class TerminologyManager:
    """æœ¯è¯­åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        self.terms = {}
        self.domain_keywords = {
            "AI": ["transformer", "attention", "neural network", "GPT", "LLM", 
                   "embedding", "tokenizer", "fine-tuning", "reinforcement learning"],
            "Math": ["derivative", "integral", "matrix", "vector", "function",
                    "equation", "theorem", "proof", "optimization"],
            "Programming": ["API", "function", "variable", "algorithm", "database",
                          "framework", "compiler", "debugger", "deployment"]
        }
    
    def extract_terms(self, text: str, target_language: str = 'ç®€ä½“ä¸­æ–‡') -> Dict[str, str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®æœ¯è¯­å¹¶ç”Ÿæˆç¿»è¯‘æ˜ å°„
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            target_language: ç›®æ ‡è¯­è¨€
        
        Returns:
            æœ¯è¯­æ˜ å°„å­—å…¸ {è‹±æ–‡: ä¸­æ–‡}
        """
        # æ£€æµ‹é¢†åŸŸ
        detected_domains = []
        text_lower = text.lower()
        
        for domain, keywords in self.domain_keywords.items():
            if any(kw.lower() in text_lower for kw in keywords):
                detected_domains.append(domain)
        
        logger.info(f"ğŸ” æ£€æµ‹åˆ°é¢†åŸŸ: {detected_domains or ['é€šç”¨']}")
        
        # ä½¿ç”¨ LLM æå–æœ¯è¯­
        prompt = f"""ä½ æ˜¯ä¸“ä¸šæœ¯è¯­æå–ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–éœ€è¦ç‰¹åˆ«æ³¨æ„ç¿»è¯‘çš„æœ¯è¯­ã€‚

è¦æ±‚ï¼š
1. æå–æŠ€æœ¯æœ¯è¯­ã€ä¸“æœ‰åè¯ã€å…³é”®æ¦‚å¿µ
2. ä¼˜å…ˆæå–ï¼š{', '.join(detected_domains)} é¢†åŸŸçš„æœ¯è¯­
3. æ¯ä¸ªæœ¯è¯­æä¾›å‡†ç¡®çš„{target_language}ç¿»è¯‘
4. è¾“å‡ºæ ‡å‡†JSONæ ¼å¼

æ–‡æœ¬ï¼ˆèŠ‚é€‰ï¼‰:
{text[:1500]}

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰ï¼š
{{
  "transformer": "Transformeræ¨¡å‹",
  "attention mechanism": "æ³¨æ„åŠ›æœºåˆ¶",
  "gradient descent": "æ¢¯åº¦ä¸‹é™"
}}"""

        try:
            client = get_client()
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šæœ¯è¯­æå–ä¸“å®¶ï¼Œç²¾é€šæŠ€æœ¯é¢†åŸŸç¿»è¯‘ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=800
            )
            
            raw = response.choices[0].message.content.strip()
            logger.debug(f"æœ¯è¯­æå–ç»“æœ: {raw[:200]}...")
            
            # è§£æJSON
            try:
                terms = json.loads(raw)
            except:
                # æ­£åˆ™æå–
                terms = {}
                matches = re.findall(r'"([^"]+)"\s*:\s*"([^"]+)"', raw)
                for en, zh in matches:
                    terms[en] = zh
            
            self.terms.update(terms)
            logger.info(f"âœ… æå–åˆ° {len(terms)} ä¸ªå…³é”®æœ¯è¯­")
            return terms
            
        except Exception as e:
            logger.warning(f"âš ï¸ æœ¯è¯­æå–å¤±è´¥: {e}")
            return {}
    
    def apply_terms(self, text: str) -> str:
        """åº”ç”¨æœ¯è¯­æ›¿æ¢ï¼ˆåå¤„ç†ï¼‰"""
        for en, zh in self.terms.items():
            # ç²¾ç¡®åŒ¹é…ï¼ˆè€ƒè™‘å¤§å°å†™ï¼‰
            pattern = re.compile(re.escape(en), re.IGNORECASE)
            text = pattern.sub(zh, text)
        return text


# ===== é«˜çº§ç¿»è¯‘å™¨ =====
class AdvancedTranslator:
    """é«˜çº§ç¿»è¯‘å™¨ï¼ˆä¸¤éç¿»è¯‘ + è´¨é‡æ ¡å¯¹ï¼‰"""
    
    def __init__(self, model_name: str = MODEL_NAME):
        self.model_name = model_name
        self.client = get_client()
        self.term_manager = TerminologyManager()
        
        # Few-shot ç¤ºä¾‹ï¼ˆæ•™å­¦ä¹ ç¿»è¯‘é£æ ¼ï¼‰
        self.few_shot_examples = [
            {
                "source": "So basically what we're doing here is taking the derivative of the loss function.",
                "target": "æ‰€ä»¥åŸºæœ¬ä¸Šæˆ‘ä»¬åœ¨è¿™é‡Œåšçš„å°±æ˜¯è®¡ç®—æŸå¤±å‡½æ•°çš„å¯¼æ•°ã€‚",
                "note": "ä¿ç•™æ‰€ä»¥ã€åŸºæœ¬ä¸Šç­‰å£è¯­åŒ–è¡¨è¾¾"
            },
            {
                "source": "This is a really cool technique that allows us to...",
                "target": "è¿™æ˜¯ä¸€ä¸ªéå¸¸é…·çš„æŠ€æœ¯ï¼Œå®ƒè®©æˆ‘ä»¬èƒ½å¤Ÿâ€¦â€¦",
                "note": "\"really cool\" ç¿»è¯‘ä¸º éå¸¸é…· è€Œé çœŸçš„å¾ˆé…· "
            },
            {
                "source": "Now, you might be wondering why we use attention here.",
                "target": "ç°åœ¨ï¼Œä½ å¯èƒ½ä¼šæƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ã€‚",
                "note": "ä¿ç•™ ä½ å¯èƒ½ä¼šæƒ³ ç­‰å¯¹è¯æ„Ÿ"
            }
        ]
    
    def build_translation_prompt(self,
                                 text: str,
                                 context_prev: List[str],
                                 context_next: List[str],
                                 terms: Dict[str, str],
                                 target_duration: float,
                                 target_language: str = 'ç®€ä½“ä¸­æ–‡') -> str:
        """æ„å»ºä¼˜åŒ–çš„ç¿»è¯‘æç¤ºè¯"""
        
        max_chars = int(target_duration * 4.5)
        
        # æœ¯è¯­åˆ—è¡¨
        term_list = "\n".join([f"- {en} â†’ {zh}" for en, zh in list(terms.items())[:15]])
        
        # Few-shot ç¤ºä¾‹
        examples = "\n\n".join([
            f"åŸæ–‡: {ex['source']}\nè¯‘æ–‡: {ex['target']}\næ³¨æ„: {ex['note']}"
            for ex in self.few_shot_examples[:2]
        ])
        
        # ä¸Šä¸‹æ–‡
        context = []
        for i, t in enumerate(context_prev, 1):
            if t: context.append(f"å‰{i}å¥: {t}")
        context.append(f"ã€å½“å‰å¥ã€‘: {text}")
        for i, t in enumerate(context_next, 1):
            if t: context.append(f"å{i}å¥: {t}")
        context_str = "\n".join(context)
        
        return f"""ä½ æ˜¯ä¸“ä¸šè§†é¢‘å­—å¹•ç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å°†è‹±æ–‡è§†é¢‘ç¿»è¯‘æˆåœ°é“ã€å£è¯­åŒ–çš„{target_language}ã€‚

# ç¿»è¯‘åŸåˆ™
1. **è‡ªç„¶æµç•…**: ç¬¦åˆ{target_language}è¡¨è¾¾ä¹ æƒ¯ï¼Œä¸è¦é€å­—ç›´è¯‘
2. **å£è¯­åŒ–**: ä¿ç•™"æ‰€ä»¥"ã€"å…¶å®"ã€"é‚£ä¹ˆ"ç­‰è¯­æ°”è¯
3. **å‡†ç¡®æ€§**: ä¸¥æ ¼ä½¿ç”¨æœ¯è¯­è¡¨ï¼Œä¿æŒå…¨æ–‡ä¸€è‡´
4. **æ—¶é•¿åŒ¹é…**: è¯‘æ–‡çº¦{target_duration:.1f}ç§’ï¼Œæœ€å¤š{max_chars}ä¸ªæ±‰å­—

# æœ¯è¯­è¡¨ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
{term_list}

# ç¿»è¯‘ç¤ºä¾‹ï¼ˆå­¦ä¹ é£æ ¼ï¼‰
{examples}

# å¾…ç¿»è¯‘å†…å®¹ï¼ˆå«ä¸Šä¸‹æ–‡ï¼‰
{context_str}

# è¾“å‡ºè¦æ±‚
ä¸¥æ ¼è¾“å‡ºJSONæ ¼å¼: {{"translation": "è¯‘æ–‡"}}
åªç¿»è¯‘ã€å½“å‰å¥ã€‘ï¼Œä¸è¦ç¿»è¯‘ä¸Šä¸‹æ–‡ï¼"""
    
    def translate_first_pass(self,
                            text: str,
                            context_prev: List[str],
                            context_next: List[str],
                            terms: Dict[str, str],
                            target_duration: float,
                            target_language: str = 'ç®€ä½“ä¸­æ–‡') -> str:
        """ç¬¬ä¸€éç¿»è¯‘ï¼ˆæ³¨é‡å‡†ç¡®æ€§ï¼‰"""
        
        prompt = self.build_translation_prompt(
            text, context_prev, context_next, terms, 
            target_duration, target_language
        )
        
        system_prompt = (
            "ä½ æ˜¯ä¸“ä¸šè§†é¢‘ç¿»è¯‘ä¸“å®¶ã€‚ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼Œ"
            "ä½¿ç”¨å£è¯­åŒ–è¡¨è¾¾ï¼Œä¿æŒæœ¯è¯­ä¸€è‡´æ€§ã€‚"
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ä¿è¯å‡†ç¡®æ€§
                top_p=0.9,
                max_tokens=250
            )
            
            raw = response.choices[0].message.content.strip()
            translation = self._parse_json(raw)
            
            return translation if translation else text
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç¬¬ä¸€éç¿»è¯‘å¤±è´¥: {e}")
            return text
    
    def refine_translation(self,
                          original: str,
                          first_translation: str,
                          target_duration: float,
                          target_language: str = 'ç®€ä½“ä¸­æ–‡') -> str:
        """ç¬¬äºŒéç¿»è¯‘ï¼ˆä¼˜åŒ–æµç•…åº¦å’Œæ—¶é•¿ï¼‰"""
        
        max_chars = int(target_duration * 4.5)
        current_chars = len(first_translation)
        
        prompt = f"""ä½ æ˜¯ç¿»è¯‘è´¨é‡å®¡æ ¡ä¸“å®¶ã€‚è¯·ä¼˜åŒ–ä»¥ä¸‹ç¿»è¯‘ï¼Œä½¿å…¶æ›´åŠ è‡ªç„¶æµç•…ã€‚

åŸæ–‡: {original}

åˆè¯‘: {first_translation}

ä¼˜åŒ–è¦æ±‚:
1. ä¿æŒåŸæ„ä¸å˜
2. æ›´åŠ å£è¯­åŒ–ã€è‡ªç„¶
3. é•¿åº¦æ§åˆ¶åœ¨ {max_chars} ä¸ªæ±‰å­—å†…ï¼ˆå½“å‰ {current_chars} å­—ï¼‰
4. å»é™¤å†—ä½™ï¼Œä½¿ç”¨æ›´ç®€æ´çš„è¡¨è¾¾
5. ç¡®ä¿æ—¶é•¿åŒ¹é…è¯­éŸ³ï¼ˆçº¦{target_duration:.1f}ç§’ï¼‰

è¾“å‡ºJSON: {{"refined": "ä¼˜åŒ–åçš„è¯‘æ–‡"}}"""

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šç¿»è¯‘å®¡æ ¡ä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,  # ç¨é«˜æ¸©åº¦å¢åŠ åˆ›é€ æ€§
                max_tokens=200
            )
            
            raw = response.choices[0].message.content.strip()
            
            # è§£ærefinedå­—æ®µ
            try:
                data = json.loads(raw)
                refined = data.get('refined', first_translation)
            except:
                match = re.search(r'"refined"\s*:\s*"((?:[^"\\]|\\.)*)"', raw)
                refined = match.group(1) if match else first_translation
            
            return refined.replace('\\"', '"').replace('\\', '')
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç¿»è¯‘ä¼˜åŒ–å¤±è´¥: {e}")
            return first_translation
    
    def _parse_json(self, raw: str) -> str:
        """è§£æJSONå“åº”"""
        try:
            data = json.loads(raw)
            return str(data.get('translation', '')).strip()
        except:
            pass
        
        # æ­£åˆ™æå–
        match = re.search(r'"translation"\s*:\s*"((?:[^"\\]|\\.)*)"', raw)
        if match:
            return match.group(1).replace('\\"', '"').replace('\\', '')
        
        return ""
    
    def translate_with_quality_check(self,
                                    text: str,
                                    context_prev: List[str],
                                    context_next: List[str],
                                    terms: Dict[str, str],
                                    target_duration: float,
                                    target_language: str = 'ç®€ä½“ä¸­æ–‡') -> Tuple[str, bool]:
        """
        å®Œæ•´ç¿»è¯‘æµç¨‹ï¼ˆä¸¤é + æ ¡å¯¹ï¼‰
        
        Returns:
            (translation, is_high_quality)
        """
        # ç¬¬ä¸€éï¼šå‡†ç¡®ç¿»è¯‘
        first_pass = self.translate_first_pass(
            text, context_prev, context_next, terms,
            target_duration, target_language
        )
        
        if not first_pass or first_pass == text:
            return text, False
        
        # ç¬¬äºŒéï¼šä¼˜åŒ–æµç•…åº¦
        refined = self.refine_translation(
            text, first_pass, target_duration, target_language
        )
        
        # åº”ç”¨æœ¯è¯­æ›¿æ¢ï¼ˆç¡®ä¿ä¸€è‡´æ€§ï¼‰
        final = self.term_manager.apply_terms(refined)
        
        # è´¨é‡æ£€æŸ¥
        is_good = self._quality_check(text, final, target_duration)
        
        return final, is_good
    
    def _quality_check(self, source: str, target: str, target_duration: float) -> bool:
        """ç®€å•çš„è´¨é‡æ£€æŸ¥"""
        if not target or len(target) < 3:
            return False
        
        # æ£€æŸ¥é•¿åº¦
        max_chars = int(target_duration * 5.0)  # å…è®¸10%è¶…å‡º
        if len(target) > max_chars:
            logger.warning(f"âš ï¸ è¯‘æ–‡è¿‡é•¿: {len(target)} > {max_chars}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªç¿»è¯‘çš„å¤§æ®µè‹±æ–‡
        english_chars = sum(1 for c in target if c.isalpha() and ord(c) < 128)
        if english_chars > len(target) * 0.3:
            logger.warning(f"âš ï¸ è‹±æ–‡å­—ç¬¦å æ¯”è¿‡é«˜: {english_chars}/{len(target)}")
            return False
        
        return True


# ===== ä¸»ç¿»è¯‘å‡½æ•° =====
def translate_advanced(folder: str, target_language: str = 'ç®€ä½“ä¸­æ–‡') -> bool:
    """
    ä½¿ç”¨é«˜çº§ç¿»è¯‘å™¨å¤„ç†å•ä¸ªè§†é¢‘
    
    Args:
        folder: è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
        target_language: ç›®æ ‡è¯­è¨€
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    translation_path = os.path.join(folder, 'translation.json')
    if os.path.exists(translation_path):
        logger.info(f"âœ… ç¿»è¯‘å·²å­˜åœ¨: {folder}")
        return True
    
    transcript_path = os.path.join(folder, 'transcript.json')
    if not os.path.exists(transcript_path):
        logger.error(f"âŒ å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {transcript_path}")
        return False
    
    # åŠ è½½å­—å¹•
    with open(transcript_path, 'r', encoding='utf-8') as f:
        transcript = json.load(f)
    
    logger.info(f"ğŸ“„ åŠ è½½äº† {len(transcript)} æ¡å­—å¹•")
    
    # åˆå§‹åŒ–ç¿»è¯‘å™¨
    translator = AdvancedTranslator()
    
    # æå–å…¨å±€æœ¯è¯­
    full_text = ' '.join(line.get('text', '') for line in transcript)
    terms = translator.term_manager.extract_terms(full_text, target_language)
    
    # ä¿å­˜æœ¯è¯­åº“
    terms_path = os.path.join(folder, 'terminology.json')
    with open(terms_path, 'w', encoding='utf-8') as f:
        json.dump(terms, f, indent=2, ensure_ascii=False)
    
    # ç¿»è¯‘æ¯æ¡å­—å¹•
    translations = []
    quality_flags = []
    
    for i, line in enumerate(transcript):
        text = line.get('text', '').strip()
        if not text:
            translations.append("")
            quality_flags.append(False)
            continue
        
        # è·å–ä¸Šä¸‹æ–‡
        context_prev = [
            transcript[j].get('text', '') 
            for j in range(max(0, i-2), i)
        ]
        context_next = [
            transcript[j].get('text', '') 
            for j in range(i+1, min(len(transcript), i+3))
        ]
        
        # è®¡ç®—ç›®æ ‡æ—¶é•¿
        start = float(line.get('start', 0))
        end = float(line.get('end', 0))
        vad_duration = line.get('vad_duration')
        target_duration = min(float(vad_duration), end - start) if vad_duration else (end - start)
        
        # è¿›åº¦æ˜¾ç¤º
        progress = (i + 1) / len(transcript) * 100
        logger.info(f"ğŸ“ˆ [{i+1}/{len(transcript)}] ({progress:.1f}%) - {text[:50]}...")
        
        # ç¿»è¯‘
        translation, is_good = translator.translate_with_quality_check(
            text, context_prev, context_next, terms,
            target_duration, target_language
        )
        
        translations.append(translation)
        quality_flags.append(is_good)
        
        logger.info(f"ğŸ’¬ è¯‘æ–‡: {translation}")
        logger.info(f"     è´¨é‡: {'âœ…' if is_good else 'âš ï¸ '} | æ—¶é•¿: {target_duration:.1f}s")
        logger.info("-" * 60)
        
        time.sleep(0.2)  # é¿å…APIé™æµ
    
    # æ„å»ºæœ€ç»ˆç»“æœ
    result = []
    for i, line in enumerate(transcript):
        result.append({
            "start": float(line.get('start', 0)),
            "end": float(line.get('end', 0)),
            "text": line.get('text', ''),
            "speaker": line.get('speaker', ''),
            "translation": translations[i]
        })
    
    # ä¿å­˜ç»“æœ
    with open(translation_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡
    total = len(quality_flags)
    success = sum(quality_flags)
    stats = {
        'total': total,
        'success': success,
        'success_rate': round(100 * success / total, 2) if total else 0
    }
    
    stats_path = os.path.join(folder, 'translation_stats.json')
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    logger.success(f"âœ… ç¿»è¯‘å®Œæˆ: {translation_path}")
    logger.info(f"ğŸ“Š æˆåŠŸç‡: {stats['success_rate']:.1f}% ({success}/{total})")
    
    return True


def translate_all_advanced(root_folder: str, target_language: str = 'ç®€ä½“ä¸­æ–‡') -> int:
    """æ‰¹é‡ç¿»è¯‘æ‰€æœ‰è§†é¢‘"""
    folders = [
        root for root, _, files in os.walk(root_folder)
        if 'transcript.json' in files and 'translation.json' not in files
    ]
    
    logger.info(f"ğŸ¯ æ‰¾åˆ° {len(folders)} ä¸ªå¾…ç¿»è¯‘è§†é¢‘")
    
    success_count = 0
    for i, folder in enumerate(folders, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ¬ å¤„ç† ({i}/{len(folders)}): {folder}")
        
        if translate_advanced(folder, target_language):
            success_count += 1
        
        if i < len(folders):
            time.sleep(2)
    
    logger.success(f"ğŸ å®Œæˆ! æˆåŠŸç¿»è¯‘ {success_count}/{len(folders)} ä¸ªè§†é¢‘")
    return success_count


if __name__ == '__main__':
    logger.remove()
    logger.add(
        sys.stderr,
        level="INFO",
        format="<green>{time:MM-DD HH:mm:ss}</green> | <level>{level: <6}</level> | <cyan>{message}</cyan>"
    )
    
    translate_all_advanced('videos', 'ç®€ä½“ä¸­æ–‡')