'''

from kokoro_onnx import Kokoro
import soundfile as sf

# âœ… æ­£ç¡®åˆå§‹åŒ–ï¼ˆæŒ‰ thewh1teagle ç‰ˆ APIï¼‰
tts = Kokoro(r"models\kokoro-onnx\kokoro-v1.0.fp16-gpu.onnx", r"models\kokoro-onnx\voices-v1.0.bin")

# åˆæˆï¼ˆæ³¨æ„ï¼šè¿”å› samples å’Œ sample_rateï¼‰
samples, sample_rate = tts.create(
    text="ä½ å¥½ï¼Œä½ æ˜¯ç…ç¬”å—ï¼ŸThis is a test of the Kokoro TTS system",
    voice="af_sky",
    speed=1.0
)

# ä¿å­˜
sf.write("output.wav", samples, sample_rate)
'''



'''
import ChatTTS
import soundfile as sf

chat = ChatTTS.Chat()
chat.load(compile=False)  # CPU æ¨¡å¼

text = "ä½ å¥½ï¼ŒHello Worldï¼ä»Šå¤©æ˜¯2026å¹´1æœˆ3æ—¥ã€‚"
wavs = chat.infer(
    text,
    params=ChatTTS.TextParams(
        speed=1.2  # è¯­é€Ÿ 1.2x
    )
)

sf.write("output.wav", wavs[0], 24000)

'''



import soundfile as sf
from voxcpm import VoxCPM

model = VoxCPM.from_pretrained("openbmb/VoxCPM-0.5B")

wav = model.generate(
    text="ä½ å¥½å•Šï¼Œè¿™ä¸ªæ˜¯ä»€ä¹ˆç³»ç»Ÿï¼ŸVoxCPM is an innovative end-to-end TTS model from ModelBest, designed to generate highly expressive speech.",
    prompt_wav_path=None,      # optional: path to a prompt speech for voice cloning
    prompt_text=None,          # optional: reference text
    cfg_value=2.0,             # LM guidance on LocDiT, higher for better adherence to the prompt, but maybe worse
    inference_timesteps=10,   # LocDiT inference timesteps, higher for better result, lower for fast speed
    normalize=True,           # enable external TN tool
    denoise=True,             # enable external Denoise tool
    retry_badcase=True,        # enable retrying mode for some bad cases (unstoppable)
    retry_badcase_max_times=3,  # maximum retrying times
    retry_badcase_ratio_threshold=6.0, # maximum length restriction for bad case detection (simple but effective), it could be adjusted for slow pace speech
)

sf.write("output.wav", wav, 16000)
print("saved: output.wav")




# test_voxcpm.py
import os
import soundfile as sf
from voxcpm import VoxCPM

print("ğŸ”Š æ­£åœ¨åŠ è½½ VoxCPM-0.5B æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œçº¦2.1GBï¼‰...")
model = VoxCPM.from_pretrained("openbmb/VoxCPM-0.5B")

# ä¸­è‹±æ··åˆæµ‹è¯•æ–‡æœ¬ï¼ˆéªŒè¯å¤šè¯­è¨€èƒ½åŠ›ï¼‰
text = "ä½ å¥½ï¼ŒHello Worldï¼æ¬¢è¿ä½¿ç”¨ VoxCPM è¯­éŸ³åˆæˆç³»ç»Ÿï¼Œè¿™æ˜¯2025å¹´å‘å¸ƒçš„å¼€æºTTSæ¨¡å‹ã€‚"

print(f"ğŸ“ è¾“å…¥æ–‡æœ¬: {text}")
print("â³ æ­£åœ¨åˆæˆè¯­éŸ³...")

wav = model.generate(
    text=text,
    normalize=True,          # å¯ç”¨æ–‡æœ¬è§„èŒƒåŒ–ï¼ˆå¤„ç†æ•°å­—ã€æ ‡ç‚¹ï¼‰
    inference_timesteps=10,  # è´¨é‡/é€Ÿåº¦å¹³è¡¡ï¼ˆ6~20ï¼‰
    cfg_value=2.0,           # éµå¾ªæ–‡æœ¬å¼ºåº¦
    denoise=False,           # å…³é—­é™å™ªï¼ˆé¿å…ä¾èµ–é¢å¤–æ¨¡å‹ï¼‰
    retry_badcase=False      # å…³é—­é‡è¯•ï¼ˆåŠ é€Ÿæµ‹è¯•ï¼‰
)

# ä¿å­˜éŸ³é¢‘
output_path = "test_voxcpm_output.wav"
sf.write(output_path, wav, 16000)

print(f"âœ… åˆæˆå®Œæˆï¼éŸ³é¢‘å·²ä¿å­˜åˆ°: {os.path.abspath(output_path)}")
print("ğŸ§ è¯·ç”¨éŸ³é¢‘æ’­æ”¾å™¨æ‰“å¼€è¯•å¬ã€‚")