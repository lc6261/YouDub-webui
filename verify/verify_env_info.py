#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒä¿¡æ¯è¯Šæ–­è„šæœ¬
ä½œè€…: Assistant
æ—¥æœŸ: 2026-01-01
ç”¨é€”: æ‰“å°å½“å‰ Python ç¯å¢ƒã€PyTorch/CUDA çŠ¶æ€ã€å¯¼å‡º requirements.txt å†…å®¹
"""

import sys
import platform
import subprocess
import os

def run_cmd(cmd):
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, encoding='utf-8', errors='replace')
        return result.stdout.strip(), result.stderr.strip()
    except Exception as e:
        return "", str(e)

def main():
    print("=" * 60)
    print("ğŸ” å½“å‰ç¯å¢ƒè¯Šæ–­æŠ¥å‘Š")
    print("=" * 60)

    # 1. Python & ç³»ç»Ÿä¿¡æ¯
    print("\n[1] Python ä¸ç³»ç»Ÿä¿¡æ¯")
    print(f"Python ç‰ˆæœ¬    : {sys.version}")
    print(f"Python è·¯å¾„    : {sys.executable}")
    print(f"å¹³å°           : {platform.platform()}")
    print(f"æ¶æ„           : {platform.machine()}")
    print(f"å½“å‰å·¥ä½œç›®å½•   : {os.getcwd()}")
    print(f"è™šæ‹Ÿç¯å¢ƒ       : {sys.prefix}")

    # 2. pip ç‰ˆæœ¬
    print("\n[2] pip ä¿¡æ¯")
    pip_out, pip_err = run_cmd("pip --version")
    if pip_out:
        print(pip_out)
    else:
        print(f"âš ï¸  pip é”™è¯¯: {pip_err}")

    # 3. PyTorch & CUDA
    print("\n[3] PyTorch ä¸ CUDA ä¿¡æ¯")
    try:
        import torch
        print(f"PyTorch ç‰ˆæœ¬     : {torch.__version__}")
        print(f"CUDA å¯ç”¨        : {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"CUDA è®¾å¤‡æ•°é‡    : {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"  - GPU {i} åç§°   : {torch.cuda.get_device_name(i)}")
            print(f"CUDA ç‰ˆæœ¬        : {torch.version.cuda}")
            print(f"cuDNN ç‰ˆæœ¬       : {torch.backends.cudnn.version()}")
        else:
            print("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é©±åŠ¨æˆ– PyTorch å®‰è£…")
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£…")
    except Exception as e:
        print(f"âš ï¸  PyTorch æ£€æµ‹å¼‚å¸¸: {e}")

    # 4. NVIDIA é©±åŠ¨ï¼ˆä»… Windows / Linuxï¼‰
    print("\n[4] NVIDIA é©±åŠ¨ä¿¡æ¯ï¼ˆå¦‚å¯è·å–ï¼‰")
    if platform.system() == "Windows":
        nvidia_out, _ = run_cmd("nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits")
        if nvidia_out:
            print(f"NVIDIA é©±åŠ¨ç‰ˆæœ¬  : {nvidia_out}")
        else:
            print("âš ï¸  æ— æ³•è·å– NVIDIA é©±åŠ¨ä¿¡æ¯ï¼ˆè¯·ç¡®è®¤ nvidia-smi æ˜¯å¦åœ¨ PATH ä¸­ï¼‰")
    elif platform.system() == "Linux":
        nvidia_out, _ = run_cmd("nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits 2>/dev/null")
        if nvidia_out:
            print(f"NVIDIA é©±åŠ¨ç‰ˆæœ¬  : {nvidia_out}")
        else:
            print("âš ï¸  æ— æ³•è·å– NVIDIA é©±åŠ¨ä¿¡æ¯ï¼ˆnvidia-smi æœªæ‰¾åˆ°ï¼‰")
    else:
        print("â„¹ï¸  é Windows/Linux ç³»ç»Ÿï¼Œè·³è¿‡ nvidia-smi æ£€æµ‹")

    # 5. å¯¼å‡º requirements.txtï¼ˆç²¾ç¡®ç‰ˆæœ¬ï¼‰
    print("\n[5] å½“å‰ç¯å¢ƒçš„ requirements.txt å†…å®¹ï¼ˆå¯ç›´æ¥å¤åˆ¶ä½¿ç”¨ï¼‰")
    print("-" * 60)
    pip_list_out, pip_list_err = run_cmd("pip list --format=freeze")
    if pip_list_out:
        # è¿‡æ»¤æ‰ä»¥ -e å¼€å¤´çš„æœ¬åœ°å¼€å‘åŒ…ï¼ˆé¿å…è·¯å¾„æ³„æ¼ï¼‰
        lines = pip_list_out.splitlines()
        clean_lines = [line for line in lines if not line.startswith("-e ")]
        for line in sorted(clean_lines):
            print(line)
    else:
        print(f"âŒ æ— æ³•è·å– pip list: {pip_list_err}")
    print("-" * 60)

    print("\nâœ… è¯Šæ–­å®Œæˆï¼ä½ å¯ä»¥å°† [5] çš„å†…å®¹ä¿å­˜ä¸º requirements.txt ä½¿ç”¨ã€‚")

if __name__ == "__main__":
    main()