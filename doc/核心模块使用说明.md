# YouDub-webui 核心模块使用说明

## 1. 概述

本文档详细介绍 YouDub-webui 系统中各个核心处理模块的使用方法、参数配置和功能说明。这些模块构成了视频中文化处理的完整流程，包括视频下载、音频分离、语音识别、字幕翻译、语音合成、视频合成、信息生成和 Bilibili 上传等步骤。

## 2. 模块列表

| 模块名称 | 模块文件 | 功能描述 |
|---------|---------|---------|
| 视频下载模块 | step000_video_downloader_csv.py | 从视频 URL 下载视频文件 |
| 音频分离模块 | step010_demucs_vr.py | 将视频中的人声与背景音乐分离 |
| 语音识别模块 | step020_whisperx_silero_vad.py | 将分离的人声转换为文本 |
| 字幕翻译模块 | step030_translation_vad_qwen.py | 将识别的文本翻译成中文 |
| 说话人分离模块 | step031_extract_speaker_clips.py | 提取不同说话人的音频片段 |
| 语音合成模块 | step040_tts_vox_cpm_qwen.py | 将翻译后的中文文本转换为语音 |
| ByteDance TTS 模块 | step041_tts_bytedance.py | 使用 ByteDance TTS 服务合成语音 |
| XTTS 语音合成模块 | step042_tts_xtts.py | 使用 XTTS 模型合成语音 |
| 视频合成模块 | step050_synthesize_video.py | 将原视频、合成语音和字幕合成为最终视频 |
| 信息生成模块 | step060_genrate_info.py | 生成视频的元数据信息 |
| Bilibili 上传模块 | step070_upload_bilibili.py | 自动将最终视频上传到 Bilibili 平台 |

## 3. 详细模块说明

### 3.1 视频下载模块 (step000_video_downloader_csv.py)

#### 3.1.1 功能描述

从视频 URL 下载视频文件，支持 YouTube 等多个平台。

#### 3.1.2 使用方法

```python
from youdub.step000_video_downloader_csv import download_video

# 单个视频下载
download_video(url, resolution, output_path)

# 从 tasks.csv 批量下载
# 运行命令：python -m youdub.step000_video_downloader_csv
```

#### 3.1.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| url | str | 视频 URL | 必填 |
| resolution | str | 视频分辨率（如 1080p） | 720p |
| output_path | str | 输出目录 | 必填 |
| cookies_file | str | cookies 文件路径 | cookies.txt |
| proxy | str | 代理配置 | None |

#### 3.1.4 输出文件

- `download.mp4`: 下载的视频文件
- `download.info.json`: 视频元数据信息
- `download.webp`: 视频缩略图

### 3.2 音频分离模块 (step010_demucs_vr.py)

#### 3.2.1 功能描述

使用 Demucs AI 模型将视频中的人声与背景音乐分离。

#### 3.2.2 使用方法

```python
from youdub.step010_demucs_vr import separate_audio

# 分离音频
separate_audio(video_path, output_path, model_name, device)

# 命令行运行
# python -m youdub.step010_demucs_vr --input <input_path> --model <model_name>
```

#### 3.2.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入视频或音频文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| model_name | str | Demucs 模型名称 | htdemucs_ft |
| device | str | 处理设备（cpu 或 cuda） | cuda |
| shifts | int | 音频分离时的移位数 | 1 |
| overlap | float | 重叠比例 | 0.25 |

#### 3.2.4 输出文件

- `audio.wav`: 分离的人声文件
- 其他分离的音频文件（如背景音乐、鼓声等，取决于模型）

### 3.3 语音识别模块 (step020_whisperx_silero_vad.py)

#### 3.3.1 功能描述

使用 WhisperX 和 Silero VAD 进行高精度语音识别，支持说话人分离。

#### 3.3.2 使用方法

```python
from youdub.step020_whisperx_silero_vad import transcribe_audio

# 语音识别
transcribe_audio(audio_path, output_path, model_name, batch_size)

# 命令行运行
# python -m youdub.step020_whisperx_silero_vad --input <audio_path> --model <model_name>
```

#### 3.3.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入音频文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| model_name | str | Whisper 模型名称 | large-v3 |
| download_root | str | 模型下载根目录 | models/whisper |
| batch_size | int | 处理批量大小 | 8 |
| device | str | 处理设备 | cuda |
| diarize | bool | 是否进行说话人分离 | True |
| min_speakers | int | 最小说话人数 | None |
| max_speakers | int | 最大说话人数 | None |

#### 3.3.4 输出文件

- `transcript.json`: 语音识别结果，包含时间戳和文本

### 3.4 字幕翻译模块 (step030_translation_vad_qwen.py)

#### 3.4.1 功能描述

将语音识别结果翻译成中文，生成字幕文件。

#### 3.4.2 使用方法

```python
from youdub.step030_translation_vad_qwen import translate_transcript

# 翻译字幕
translate_transcript(transcript_path, output_path, target_language)

# 命令行运行
# python -m youdub.step030_translation_vad_qwen --input <transcript_path> --target-language zh
```

#### 3.4.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入 transcript.json 文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| target_language | str | 目标语言 | zh |
| model_name | str | 翻译模型名称 | gpt-3.5-turbo |
| api_key | str | API 密钥 | 从 .env 文件读取 |
| api_base | str | API 基础 URL | 从 .env 文件读取 |

#### 3.4.4 输出文件

- `translation.json`: 翻译结果
- `subtitles.srt`: SRT 字幕文件

### 3.5 说话人分离模块 (step031_extract_speaker_clips.py)

#### 3.5.1 功能描述

从音频中提取不同说话人的音频片段，用于语音合成参考。

#### 3.5.2 使用方法

```python
from youdub.step031_extract_speaker_clips import extract_speaker_clips

# 提取说话人片段	extract_speaker_clips(audio_path, transcript_path, output_path)

# 命令行运行
# python -m youdub.step031_extract_speaker_clips --input <audio_path> --transcript <transcript_path>
```

#### 3.5.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入音频文件路径 | 必填 |
| transcript_path | str | 输入 transcript.json 文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| min_duration | float | 最小片段时长（秒） | 2.0 |
| max_duration | float | 最大片段时长（秒） | 10.0 |

#### 3.5.4 输出文件

- `SPEAKER/` 目录：包含不同说话人的音频片段

### 3.6 语音合成模块 (step040_tts_vox_cpm_qwen.py)

#### 3.6.1 功能描述

使用 VoxCPM 模型将翻译后的中文文本转换为语音。

#### 3.6.2 使用方法

```python
from youdub.step040_tts_vox_cpm_qwen import synthesize_speech

# 合成语音
synthesize_speech(translation_path, audio_path, output_path)

# 命令行运行
# python -m youdub.step040_tts_vox_cpm_qwen --input <translation_path> --audio <audio_path>
```

#### 3.6.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入 translation.json 文件路径 | 必填 |
| audio_path | str | 输入音频文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| model_name | str | VoxCPM 模型名称 | voxcpm-0.5b |
| device | str | 处理设备 | cuda |
| speaker_id | int | 说话人 ID | 0 |
| speed | float | 语速调整 | 1.0 |
| pitch | float | 音调调整 | 0.0 |

#### 3.6.4 输出文件

- `audio_tts.wav`: 合成的语音文件

### 3.7 ByteDance TTS 模块 (step041_tts_bytedance.py)

#### 3.7.1 功能描述

使用 ByteDance TTS 服务合成语音。

#### 3.7.2 使用方法

```python
from youdub.step041_tts_bytedance import synthesize_speech_bytedance

# 合成语音
synthesize_speech_bytedance(translation_path, output_path, api_key)

# 命令行运行
# python -m youdub.step041_tts_bytedance --input <translation_path> --api-key <api_key>
```

#### 3.7.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入 translation.json 文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| api_key | str | ByteDance API 密钥 | 从 .env 文件读取 |
| voice | str | 语音类型 | zh-CN-YunxiNeural |
| speed | float | 语速调整 | 1.0 |
| pitch | float | 音调调整 | 0.0 |

#### 3.7.4 输出文件

- `audio_tts.wav`: 合成的语音文件

### 3.8 XTTS 语音合成模块 (step042_tts_xtts.py)

#### 3.8.1 功能描述

使用 XTTS 模型合成语音，支持多语言和声音克隆。

#### 3.8.2 使用方法

```python
from youdub.step042_tts_xtts import synthesize_speech_xtts

# 合成语音
synthesize_speech_xtts(translation_path, reference_audio, output_path)

# 命令行运行
# python -m youdub.step042_tts_xtts --input <translation_path> --reference <reference_audio>
```

#### 3.8.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入 translation.json 文件路径 | 必填 |
| reference_audio | str | 参考音频文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| model_name | str | XTTS 模型名称 | xtts_v2 |
| device | str | 处理设备 | cuda |
| language | str | 目标语言 | zh-cn |
| speed | float | 语速调整 | 1.0 |

#### 3.8.4 输出文件

- `audio_tts.wav`: 合成的语音文件

### 3.9 视频合成模块 (step050_synthesize_video.py)

#### 3.9.1 功能描述

将原视频、合成语音和字幕合成为最终视频。

#### 3.9.2 使用方法

```python
from youdub.step050_synthesize_video import synthesize_video

# 合成视频
synthesize_video(video_path, tts_audio_path, subtitles_path, output_path)

# 命令行运行
# python -m youdub.step050_synthesize_video --input <video_path> --audio <tts_audio_path> --subtitles <subtitles_path>
```

#### 3.9.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入视频文件路径 | 必填 |
| audio_path | str | 输入合成语音文件路径 | 必填 |
| subtitles_path | str | 输入字幕文件路径 | None |
| output_path | str | 输出目录 | 必填 |
| fps | int | 视频帧率 | 30 |
| speed_up | float | 视频加速比例 | 1.0 |
| resolution | str | 输出视频分辨率 | 1080p |
| codec | str | 视频编码格式 | libx264 |
| bitrate | str | 视频比特率 | 8M |

#### 3.9.4 输出文件

- `video.mp4`: 最终合成的视频文件

### 3.10 信息生成模块 (step060_genrate_info.py)

#### 3.10.1 功能描述

生成视频的元数据信息，包括标题、描述、标签等。

#### 3.10.2 使用方法

```python
from youdub.step060_genrate_info import generate_video_info

# 生成视频信息
generate_video_info(video_path, translation_path, output_path)

# 命令行运行
# python -m youdub.step060_genrate_info --input <video_path> --translation <translation_path>
```

#### 3.10.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入视频文件路径 | 必填 |
| translation_path | str | 输入 translation.json 文件路径 | 必填 |
| output_path | str | 输出目录 | 必填 |
| template_path | str | 信息模板文件路径 | None |

#### 3.10.4 输出文件

- `video.txt`: 视频描述文本
- `video.png`: 视频缩略图
- 其他元数据文件

### 3.11 Bilibili 上传模块 (step070_upload_bilibili.py)

#### 3.11.1 功能描述

自动将最终视频上传到 Bilibili 平台。

#### 3.11.2 使用方法

```python
from youdub.step070_upload_bilibili import upload_to_bilibili

# 上传视频
upload_to_bilibili(video_path, title, description, tags)

# 命令行运行
# python -m youdub.step070_upload_bilibili --input <video_path> --title <title> --description <description>
```

#### 3.11.3 参数说明

| 参数名称 | 类型 | 描述 | 默认值 |
|---------|------|------|--------|
| input_path | str | 输入视频文件路径 | 必填 |
| title | str | 视频标题 | 必填 |
| description | str | 视频描述 | "" |
| tags | list | 视频标签 | [] |
| category_id | int | 视频分类 ID | 171 |
| privacy | int | 隐私设置（0-公开，1-私密，2-仅粉丝可见） | 0 |
| cover_path | str | 封面图片路径 | None |

#### 3.11.4 输出结果

- 返回 Bilibili 视频 ID 和播放链接

## 4. 批量处理使用方法

### 4.1 配置 tasks.csv 文件

批量处理通过 `tasks.csv` 文件配置，格式如下：

```csv
url,resolution,mode,status,title,duration,video_id,publish_date,uploader,progress,start_time,end_time,output_path,error_message,task_type,steps
https://www.youtube.com/shorts/ieW8-Qjs5rU,1080p,all,pending,视频标题,60,ieW8-Qjs5rU,20251114,上传者,,,,,download_only,0
https://www.youtube.com/watch?v=dBap_Lp-0oc,1080p,all,pending,视频标题,1016,dBap_Lp-0oc,20201231,上传者,,,,,full_process,0,1,2,3,4,5,6,7
```

### 4.2 运行批量处理

```bash
# 激活虚拟环境
venv\Scripts\activate

# 运行完整处理管道
python -m youdub.run_pipeline --use-task-steps

# 仅运行特定步骤
python -m youdub.run_pipeline --use-task-steps --steps 0,1,2
```

### 4.3 监控任务状态

```bash
# 检测任务完成情况
python check_tasks_completion.py

# 从现有视频重建任务
python recreate_tasks.py
```

## 5. 常见问题与解决方案

### 5.1 模块运行失败

- **问题**: 模块运行时出现错误
- **解决方案**: 查看日志文件，检查参数配置是否正确，确保依赖项已安装

### 5.2 处理速度慢

- **问题**: 处理单个视频耗时过长
- **解决方案**: 使用 GPU 加速，降低模型复杂度，减少批量大小

### 5.3 语音合成质量不佳

- **问题**: 合成的语音不自然
- **解决方案**: 尝试不同的 TTS 模型，调整语速、音调参数，提供更好的参考音频

### 5.4 字幕不同步

- **问题**: 字幕与视频不同步
- **解决方案**: 检查语音识别结果的时间戳，调整视频合成参数

## 6. 性能优化建议

1. **使用 GPU 加速**: 确保 CUDA 环境正确配置，使用 GPU 加速 AI 模型推理
2. **合理选择模型**: 根据硬件条件选择合适大小的模型
3. **批量处理**: 使用 tasks.csv 进行批量处理，提高效率
4. **缓存中间结果**: 避免重复处理相同的视频
5. **并行处理**: 调整 max_workers 参数，充分利用 CPU 核心

## 7. 总结

YouDub-webui 的核心模块提供了完整的视频中文化处理流程，每个模块都可以独立使用或组合使用。通过合理配置参数和选择模型，可以获得高质量的中文视频输出。批量处理功能支持大规模视频处理，提高了工作效率。

对于不同的使用场景，可以灵活组合各个模块，定制适合自己需求的处理流程。