# YouDub-webui 项目使用指南

## 1. 项目介绍

YouDub-webui 是一个基于 AI 技术的视频中文化工具，能够将 YouTube 等平台上的高质量视频自动下载、翻译、配音并合成为中文视频。该工具结合了先进的语音识别、机器翻译和语音合成技术，提供了完整的视频本地化解决方案。

## 2. 环境要求

### 2.1 硬件要求
- **CPU**: 至少 4 核处理器
- **GPU**: NVIDIA GPU（推荐，用于加速 AI 处理）
- **内存**: 至少 8GB RAM
- **存储空间**: 至少 50GB 可用空间

### 2.2 软件要求
- **操作系统**: Windows 10/11
- **Python 版本**: Python 3.10 或更高版本
- **Git**: 用于克隆仓库

## 3. 安装步骤

### 3.1 克隆仓库

1. 安装 Git：从 [Git 官网](https://git-scm.com/) 下载并安装 Git
2. 打开命令提示符 (CMD) 或 PowerShell
3. 运行以下命令克隆仓库：

```bash
git clone https://github.com/liuzhao1225/YouDub-webui.git
cd YouDub-webui
```

### 3.2 安装依赖

#### 3.2.1 自动安装（推荐小白使用）

1. 双击运行 `setup_windows.bat` 文件
2. 等待安装完成，脚本会自动创建虚拟环境并安装所有依赖
3. 安装过程可能需要几分钟，请耐心等待

#### 3.2.2 手动安装

1. 打开命令提示符，进入项目目录
2. 创建虚拟环境：

```bash
python -m venv venv
```

3. 激活虚拟环境：

```bash
venv\Scripts\activate
```

4. 安装基础依赖：

```bash
pip install -r requirements.txt
```

5. 安装 TTS 依赖：

```bash
pip install TTS
```

### 3.3 配置环境变量

1. 将 `.env.example` 文件复制一份并重命名为 `.env`
2. 使用文本编辑器（如 Notepad++）打开 `.env` 文件
3. 填写所需的环境变量：

| 变量名 | 说明 | 示例值 |
|-------|------|--------|
| OPENAI_API_KEY | OpenAI API 密钥（用于翻译，可选） | sk-xxx |
| MODEL_NAME | 翻译模型名称 | gpt-3.5-turbo |
| HF_TOKEN | Hugging Face token（用于说话者分离，可选） | hf_xxx |
| APPID | 火山引擎 TTS 凭据（可选） | xxx |
| ACCESS_TOKEN | 火山引擎 TTS 凭据（可选） | xxx |
| BILI_BASE64 | Bilibili 上传凭据（可选） | xxx |

## 4. 启动程序

### 4.1 使用启动脚本（推荐）

1. 双击运行 `run_windows.bat` 文件
2. 等待程序启动，会自动打开浏览器
3. 在浏览器中使用 WebUI 进行操作

### 4.2 手动启动

1. 打开命令提示符，进入项目目录
2. 激活虚拟环境：

```bash
venv\Scripts\activate
```

3. 启动 WebUI：

```bash
python app.py
```

4. 在浏览器中访问显示的 URL（通常是 http://127.0.0.1:7860）

## 5. 基本使用流程

### 5.1 单视频处理

1. 在 WebUI 中选择 "全自动 (Do Everything)" 选项卡
2. 填写以下参数：
   - **Video URL**: 输入视频 URL（如 https://www.youtube.com/watch?v=dBap_Lp-0oc）
   - **Resolution**: 选择视频分辨率（如 1080p）
   - **Whisper Model**: 选择语音识别模型（推荐 large-v3）
   - **Translation Target Language**: 选择目标语言（中文）
   - 其他参数可保持默认值
3. 点击 "Run" 按钮开始处理
4. 等待处理完成，查看输出视频

### 5.2 批量处理

1. 编辑 `tasks.csv` 文件，添加要处理的视频信息
2. 每行代表一个任务，包含以下字段：
   - url: 视频 URL
   - resolution: 视频分辨率
   - mode: 处理模式（all）
   - status: 任务状态（pending, processing, completed）
   - task_type: 任务类型（download_only 或 full_process）
   - steps: 执行步骤（0 或 0,1,2,3,4,5,6,7）
3. 保存 `tasks.csv` 文件
4. 运行批量处理命令：

```bash
venv\Scripts\activate
python -m youdub.run_pipeline --use-task-steps
```

5. 等待所有任务处理完成

### 5.3 监控任务状态

```bash
# 检测任务完成情况
python check_tasks_completion.py

# 从现有视频重建任务
python recreate_tasks.py
```

## 6. 功能模块说明

### 6.1 视频下载

- **功能**: 从视频 URL 下载视频文件
- **支持平台**: YouTube、Bilibili 等
- **输出文件**: download.mp4, download.info.json, download.webp

### 6.2 音频分离

- **功能**: 将视频中的人声与背景音乐分离
- **技术**: 使用 Demucs AI 模型
- **输出**: 分离的人声和背景音乐文件

### 6.3 语音识别

- **功能**: 将分离的人声转换为文本
- **技术**: WhisperX + Silero VAD
- **特点**: 高精度、支持说话者分离
- **输出**: transcript.json（包含时间戳和文本）

### 6.4 字幕翻译

- **功能**: 将识别的文本翻译成中文
- **技术**: 大型语言模型（如 GPT）
- **输出**: translation.json, subtitles.srt

### 6.5 语音合成

- **功能**: 将翻译后的中文文本转换为语音
- **支持模型**: VoxCPM、ByteDance TTS、XTTS
- **特点**: 自然流畅、支持声音克隆
- **输出**: audio_tts.wav

### 6.6 视频合成

- **功能**: 将原视频、合成语音和字幕合成为最终视频
- **技术**: FFmpeg
- **输出**: video.mp4

### 6.7 Bilibili 上传

- **功能**: 自动将最终视频上传到 Bilibili 平台
- **条件**: 需要配置 Bilibili 凭据

## 7. 输出文件说明

| 文件名称 | 说明 | 所在目录 |
|---------|------|---------|
| download.mp4 | 下载的原始视频 | 视频输出目录 |
| download.info.json | 视频元数据信息 | 视频输出目录 |
| download.webp | 视频缩略图 | 视频输出目录 |
| audio.wav | 分离的人声 | 视频输出目录 |
| transcript.json | 语音识别结果 | 视频输出目录 |
| translation.json | 翻译结果 | 视频输出目录 |
| subtitles.srt | 字幕文件 | 视频输出目录 |
| audio_tts.wav | 合成的语音 | 视频输出目录 |
| video.mp4 | 最终合成视频 | 视频输出目录 |

## 8. 常见问题与解决方案

### 8.1 程序无法启动

**问题**: 双击 run_windows.bat 后没有反应

**解决方案**:
- 检查 Python 是否正确安装
- 检查虚拟环境是否创建成功
- 尝试手动启动，查看错误信息

### 8.2 视频下载失败

**问题**: 无法下载视频，显示错误信息

**解决方案**:
- 检查网络连接
- 确保视频 URL 正确
- 尝试使用不同的视频 URL
- 检查是否需要代理配置

### 8.3 处理速度很慢

**问题**: 处理单个视频耗时过长

**解决方案**:
- 使用 GPU 加速（确保 CUDA 环境正确配置）
- 降低模型复杂度（如使用较小的 Whisper 模型）
- 减少批量大小
- 关闭说话者分离功能

### 8.4 语音合成质量不佳

**问题**: 合成的语音不自然

**解决方案**:
- 尝试不同的 TTS 模型
- 调整语速、音调参数
- 提供更好的参考音频
- 确保输入文本质量良好

### 8.5 字幕不同步

**问题**: 字幕与视频不同步

**解决方案**:
- 检查语音识别结果的时间戳
- 调整视频合成参数
- 重新运行语音识别步骤

## 9. 性能优化建议

1. **使用 GPU 加速**: 确保 CUDA 环境正确配置，使用 GPU 加速 AI 模型推理
2. **合理选择模型**: 根据硬件条件选择合适大小的模型
3. **批量处理**: 使用 tasks.csv 进行批量处理，提高效率
4. **关闭不必要的功能**: 如不需要说话者分离，可以关闭该功能
5. **清理临时文件**: 定期清理 videos 目录下的临时文件

## 10. 高级功能

### 10.1 自定义处理流程

- 可以单独运行各个处理步骤
- 在 WebUI 中选择对应的选项卡
- 按照提示填写参数，运行单个步骤

### 10.2 调整处理参数

- 在 WebUI 中可以调整各种处理参数
- 如模型选择、批量大小、设备选择等
- 根据需要调整以获得更好的处理效果

### 10.3 使用不同的 TTS 模型

- 支持 VoxCPM、ByteDance TTS、XTTS 等多种 TTS 模型
- 在 WebUI 中选择对应的 TTS 模块
- 按照提示填写参数，运行 TTS 合成

## 11. 项目结构

```
YouDub-webui/
├── videos/                          # 视频输出目录
├── youdub/                          # 核心功能模块
├── .env                             # 环境配置文件
├── app.py                           # WebUI 主程序
├── check_tasks_completion.py        # 任务完成检测脚本
├── recreate_tasks.py                # 任务重建脚本
├── requirements.txt                 # 依赖清单
├── run_windows.bat                  # Windows 启动脚本
├── setup_windows.bat                # Windows 安装脚本
└── tasks.csv                        # 批量任务配置文件
```

## 12. 注意事项

1. **版权问题**: 请遵守版权法规，仅用于合法用途
2. **API 费用**: 使用某些服务（如 OpenAI API）可能会产生费用
3. **硬件要求**: 高质量的 AI 模型需要较强的硬件支持
4. **网络连接**: 首次运行需要下载模型文件，需要良好的网络连接
5. **存储空间**: 处理视频会占用大量存储空间，请确保有足够的可用空间

## 13. 更新与维护

### 13.1 更新项目

```bash
git pull origin master
```

### 13.2 更新依赖

```bash
pip install -r requirements.txt --upgrade
```

### 13.3 日志查看

- 查看 logs 目录下的日志文件
- 运行时的日志会显示在命令行窗口

## 14. 支持与反馈

- **GitHub Issues**: [提交问题](https://github.com/liuzhao1225/YouDub-webui/issues)
- **Discord 服务器**: [加入讨论](https://discord.gg/vbkYnN2Rrm)
- **微信群**: 扫描项目 README.md 中的二维码加入

## 15. 总结

YouDub-webui 是一个功能强大的视频中文化工具，能够帮助用户快速将国外视频本地化。通过本使用指南，您应该已经了解了项目的安装、配置和基本使用方法。

对于小白用户，建议从单视频处理开始，逐步熟悉各个功能模块。随着对项目的了解，可以尝试使用批量处理功能，提高工作效率。

祝您使用愉快！